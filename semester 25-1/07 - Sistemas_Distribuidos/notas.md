- #### Clase del día - 27/08/2024
    
    #### 
    
    ##### **Bienvenidos al curso de Sistemas Distribuidos**
    
      
    
    En este curso vamos a estudiar cómo diseñar e implementar soluciones tecnológicas confiables y escalables utilizando servicios en la nube.
    
      
    
    Imagen generada con tecnología DALL-E3  
    
    "In this architecture (Cloud computing) the data is mostly resident on servers 'somewhere on the Internet' and the application runs on both the 'cloud servers' and the user's browser. When you use Google Gmail, Maps, Yahoo's services, many of eBay's services, you are using this architecture." ..."The consequence of this 'architectural shift' is the return of massive data centers." [Eric Schmidt, former CTO Sun Microsystems] _The Information Factories_, George Gilder, 2006.
    
    **Vamos utilizar el cómputo en la nube**  
    
    Actualmente todos usamos algún servicio en la nube.
    
    Por ejemplo Hotmail, Gmail, Youtube, Uber, Netflix y Office 365 son ejemplos de servicios en la nube. También Google Drive y OneDrive son servicios en la nube.
    
    Los primeros son aplicaciones (distribuidas) que ejecutan en la nube y los segundos son servicios de almacenamiento en la nube.
    
    Las empresas están migrando sus sistemas a la nube, por esa razón es muy importante que los egresados de la ESCOM puedan desarrollar, instalar y administrar sistemas en la nube.
    
    En nuestro curso vamos a utilizar la nube de Microsoft llamada Azure. Para ello **es necesario que todos** se inscriban al programa gratuito [Azure for Students](https://azure.microsoft.com/es-es/free/students/) mediante su cuenta de correo institucional.
    
    En este programa Microsoft les regala 100 dólares en servicios de nube de Azure durante un año, sin la necesidad de dar una tarjeta de crédito. Solo es necesario demostrar su condición de alumno (mediante la cuenta de correo institucional).
    
    Inicialmente vamos a explicar cómo configurar redes en la nube y cómo crear máquinas virtuales (Linux y Windows).
    
    También veremos como crear imágenes de máquinas virtuales, respaldos, instancias de DBMS, balanceadores de carga, firewall, serverless, microservicios basados en contenedores Docker, replicación de un sistema completo, almacenamiento masivo, Internet de las cosas (IoT), Google maps, business intelligence, entre otros servicios en la nube.
    
    Debido a que 100 dólares no es mucho en recursos de nube, deberemos tener cuidado en detener o eliminar los recursos en la nube tan pronto realicemos alguna prueba o tarea.  
    
    Más allá de la teoría "by the book", vamos a aterrizar los temas del curso en casos de uso prácticos en la nube. Esto les dará una ventaja competitiva importante al integrarse a la industria.
    
      
    
    **Vamos a programar en Java, HTML-Javascript y C#**  
    
    Además de ver la teoría, vamos a desarrollar, utilizando Java, HTML-Javascript y C#, sistemas distribuidos que ejecutarán en la nube.
    
      
    
    En el mapa curricular 2020, la asignatura "Sistemas Distribuidos" depende de la asignatura "Aplicaciones para Comunicaciones en Red"; en esta materia se explica cómo programar un cliente y un servidor mediante sockets (inseguros) y cómo programar una aplicación multi-thread, sin embargo, el mapa curricular 2020 solo incluye los temas de comunicación segura (sockets seguros, IPsec, HTTPS, certificados digitales, etc.) en la materia optativa "Selected topics in Cryptography", la cual requiere cursar otra materia optativa: "Introduction to Cryptography".  
    
      
    
    La arquitectura cliente/servidor es la base de la mayoría de los sistemas distribuidos, por tanto, repasaremos cómo programar un cliente y un servidor multi-thread.
    
      
    
    Debido a que la comunicación segura es imprescindible en los sistemas distribuidos modernos, también vamos a ver cómo programar clientes y servidores con sockets seguros y cómo implementar un servidor HTTPS.
    
      
    
    **Vamos a utilizar una Inteligencia Artificial Generativa**
    
      
    
    Vamos a utilizar una Inteligencia Artificial Generativa (IAG), p.e. [ChatGPT](https://openai.com/chatgpt), [Copilot](https://www.bing.com/copilot?cc=es&setlang=es) o [Gemini](https://bard.google.com/), como apoyo para el desarrollo y configuración de servicios en la nube.
    
    El uso de una IAG requiere que los alumnos y las alumnas entiendan el problema a resolver, y así puedan explicarlo a la IAG mediante un prompt.
    
    Los alumnos y las alumnas deberán explicar a la IAG los requerimientos mediante un prompt, entonces deberán revisar la respuesta generada por la IAG y corregir manualmente lo que no sea correcto, o bien, interactuar con la IAG para que realice las correcciones.  
    
    El proceso de desarrollo utilizando IAG requiere que los alumnos y las alumnas **entiendan el problema** a resolver, y así **puedan explicarlo a la IAG** mediante un prompt.  
    
    Los alumnos y las alumnas deberán ser críticos ante las respuestas de la IAG y revisar estos resultados antes de aplicarlos.
    
    A la habilidad de redactar preguntas para un modelo de lenguaje, las cuales permitan obtener mejores respuestas, se le llama **p****rompt engineering**.
    
    Los alumnos y las alumnas deben aprender esta nueva habilidad ya que en el ámbito laboral el uso de esta tecnología representa una importante ventaja competitiva.
    
      
    
    **Vamos a jugar  
    **
    
    En nuestro curso vamos a implementar la "gamificación" (game=juego) como apoyo didáctico.
    
    Vamos a jugar [kahoots](https://kahoot.com/schools-u/) sobre los temas del curso. A los ganadores de cada kahoot se les otorgarán puntos directos a la calificación parcial; 1/2 de punto al primer lugar, 1/4 de punto al segundo lugar y 1/8 de punto al tercer lugar.
    
    Se agregará a la calificación del parcial, los puntos por kahoots que cada alumno o alumna ganó en el mismo parcial.
    
    Cada alumno o alumna solo podrá aplicar un máximo de 1.5 puntos extra por gamificación cada parcial.
    
    Jugar los kahoots será opcional, pero es conveniente que todos participen, ya que jugar sirve para repasar los temas vistos en clase, además de la posibilidad de ganar puntos extra.
    
    Si se sobrepasa la calificación de 10 después de agregar los puntos por gamificación, la calificación que se asentará en el parcial será 10, el excedente no se aplicará a los siguientes parciales. Los puntos por gamificación no son transferibles a los siguientes parciales.
    
    **Evaluación parcial**  
    
    Cada parcial se evaluará de la siguiente forma:
    
    - Tareas (70%)
    - Examen (20%)
    - Participación en clase (10%)
    - Puntos extra
    
      
    
    Las tareas se deberán entregar en tiempo y forma en la plataforma Moodle.
    
    No habrá extensión en la fecha de entrega de las tareas, salvo causas plenamente justificadas.
    
    Se recomienda realizar las tareas tan pronto se publiquen en Moodle, de tal manera que si tienen alguna duda, puedan consultar con el profesor.
    
    Como pueden ver, las tareas tienen la mayor ponderación en la calificación.
    
    **Asesorías**  
    
    Las asesorías se llevaran a cabo mediante videoconferencia acordando previamente la fecha y hora para la realización de la sesión.
    
    Para acceder a las sesiones de asesoría se deberá ingresar al enlace Acceso a la sesión de asesoría disponible en la plataforma Moodle.
    
    **Clase del día**
    
    El profesor publicará en la plataforma Moodle la explicación del tema tratado en cada clase presencial. El contenido se titulará “Clase del día”.  
    
      
    
    De acuerdo al calendario académico del IPN, no se publicará la “Clase del día” los días no laborables. Sin embargo, se podrá acceder a la plataforma Moodle los días no laborables para estudiar las clases, realizar las actividades y tareas.  
    
    **Referencias**
    
      
    
    1. _Cloud Computing: Concepts, Technology & Architecture,_ Thomas Erl, Ricardo Puttini, Zaigham Mahmood, Ed. ServiceTech Press, 2013.
    2. _Mastering Cloud Computing: Foundations and Applications Programming_, Buyya, Rajkumar, Vecchiola, Christian, Ed. MK, 2013.  
        
    3. _Webservices, Theory and Practice_, Hrushikesha Mohanty, Prasant Kumar, Ed. Springer, 2018.
    4. _Azure Networking Cookbook, 2nd. Ed._, Mustafa Toroman, Packt Publishing, 2020.
    5. _Java Course_, [http://youtube.com/watch?v=coK4jM5wvko&t=4s](http://youtube.com/watch?v=coK4jM5wvko&t=4s)
    
      
    
    ##### Actividades individuales a realizar
    
      
    
    1. Obtener una cuenta de correo institucional del IPN.
    2. Darse de alta en el programa [Azure for Students](https://azure.microsoft.com/es-es/free/students/).
    3. Instalar en su computadora el JDK8 o superior.
    
      
    
    ![No finalizado; Clase del día - 27/08/2024Bienvenidos al curso de .... Seleccione para marcar como finalizado](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/i/completion-manual-n "No finalizado; Clase del día - 27/08/2024Bienvenidos al curso de .... Seleccione para marcar como finalizado")
    
- #### Clase del día - 28/08/2024
    
      
    **Arquitectura Cliente - Servidor  
    **  
    
    La clase de hoy vamos a ver cómo programar un cliente y un servidor en Java.
    
    Un cliente es un programa que **se conecta** a un programa servidor. Notar que el cliente inicia la conexión con el servidor.
    
      
    
    Una vez que el cliente está conectado al servidor, el cliente puede enviar datos al servidor y el servidor puede mandar datos al cliente. A este tipo de comunicación se le conoce como **bi-direccional**, debido a que los datos pueden fluir en ambas direcciones.  
    
    En particular, los clientes y servidores que utilizaremos en el curso usan sockets TCP.
    
    Para compilar y ejecutar los programas del curso vamos a utilizar JDK8 desde la línea de comandos.
    
    Los que quieran utilizar ambientes de desarrollo como Netbeans o Eclipse pueden hacerlo, sin embargo en la clase vamos a ejecutar los programas en la línea de comandos.
    
    **Cliente.java**
    
    El programa **Cliente.java** es un ejemplo de un cliente de sockets TCP que se conecta a un servidor y posteriormente envía y recibe datos.
    
    Primeramente vamos a crear un socket que se conectará al servidor. En este caso el servidor se llama "localhost" (computadora local) y el puerto abierto en el servidor es el 50000.  
      
    En general el nombre del servidor puede ser un nombre de dominio (como midominio.com o una dirección IP). El número de puerto es un número entero entre 0 y 65535.
    
    Socket conexion = new Socket("localhost",50000);
    
    En este caso declaramos una variable de tipo Socket llamada "conexión" la cual va a contener una instancia de la clase Socket.
    
    Es importante aclarar que antes de crear el socket, el programa servidor debe estar en ejecución y esperando una conexión, de otra manera la instrucción anterior produce una excepción, la cual desde luego debería controlarse dentro de un bloque **try**.  
    
    Para enviar datos al servidor a través del socket, vamos a crear un stream de salida de la siguiente manera:
    
    DataOutputStream salida = new DataOutputStream(conexion.getOutputStream());
    
    De la misma forma, para leer los datos que envía el servidor a través del socket, creamos un stream de entrada:
    
    DataInputStream entrada = new DataInputStream(conexion.getInputStream());
    
    Ahora podemos enviar y recibir datos del servidor. Veamos algunos ejemplos.
    
    Vamos a enviar un entero de 32 bits, en este caso el número 123, utilizando el método **writeInt**:
    
    salida.writeInt(123);
    
    Ahora vamos a enviar un número punto flotante de 64 bits utilizando el método **writeDouble**:
    
    salida.writeDouble(1234567890.1234567890);
    
    Vamos a enviar  la cadena de caracteres "hola":
    
    salida.write("hola".getBytes());
    
    Debido a que el método **write** envía un arreglo de bytes, para enviar la cadena de caracteres "hola" es necesario convertirla a arreglo de bytes mediante el método **getBytes**.  
      
    Por omisión el método **getBytes** utiliza la codificación default (UTF-8), para usar otra codificación se puede pasar como parámetro el nombre de la codificación como string, por ejemplo "UTF-8".
    
    Ahora supongamos que el servidor envía al cliente una cadena de caracteres.
    
    Para que el cliente reciba la cadena de caracteres es necesario que conozca el número de bytes que envía el servidor, en este caso el servidor envía una cadena de caracteres de 4 bytes.
    
    Para recibir los bytes se utiliza el método **read** de la clase DataInputStream. El método **read** tiene tres parámetros, el primer parámetro es un arreglo de bytes con una longitud suficiente para contener los bytes a recibir.
    
    El segundo parámetro indica la posición, dentro del arreglo de bytes, donde se pondrán los bytes a recibir, y el tercer parámetro indica el número de bytes a recibir.
    
    El siguiente código crea un arreglo de 4 bytes, invoca el método **read** de la clase DataInputStream, crea una instancia de la clase String utilizando los bytes recibidos.
    
    Debido a que la variable buffer contiene los bytes correspondientes a la cadena de caracteres que envió el servidor, para obtener la cadena de caracteres utilizamos el constructor de la clase String para crear una cadena de caracteres a partir del arreglo de bytes indicando la codificación, en este caso UTF-8.  
    
    byte[] buffer = new byte[4];
    entrada.read(buffer,0,4);
    System.out.println(new String(buffer,"UTF-8"));
    
    Sin embargo es necesario considerar que el método **read** podría obtener solo una parte del mensaje enviado.  
    
    Es un error muy común de los programadores creer que el método **read** siempre regresa el mensaje completo.  
    
    En realidad cuando un mensaje es largo, el método **read** debe ser invocado repetidamente hasta recibir el mensaje completo.
    
    Para recibir el mensaje completo implementaremos un nuevo método **read** de la siguiente manera:
    
    static void read(DataInputStream f,byte[] b,int posicion,int longitud) throws Exception
    {
      while (longitud > 0)
      {
        int n = f.read(b,posicion,longitud);
        posicion += n;
        longitud -= n;
      }
    }
    
    En este caso, el método estático **read** regresará el mensaje completo en el arreglo de bytes "b".  
      
    Notar que el método **read** de la clase DataInputStream regresa el número de bytes efectivamente leídos.  
      
    Debido a que el método **read** de la clase DataInputStream puede producir una excepción, es necesario invocar este método dentro de un bloque try o bien. se debe utilizar la cláusula **throws** en el prototipo del método.
    
    Para recibir la cadena de caracteres que envía el servidor,  vamos a invocar el método estático **read**:
    
    byte[] buffer = new byte[4];
    read(entrada,buffer,0,4);
    System.out.println(new String(buffer,"UTF-8"));
    
      
    
    **Los métodos writeUTF y readUTF**
    
    Para enviar y recibir strings entre programas escritos en Java, se puede utilizar el método **writeUTF** de la clase DataOutputStream y el método **readUTF** de la clase DataInputStream.
    
    El método **writeUTF** convierte la string a arreglo de bytes utilizando el método **getBytes**("UTF-8") de la clase String, escribe al stream de salida la longitud del arreglo de bytes utilizando el método **writeShort** y escribe al stream de salida los bytes utilizando el método **write**.
    
    El método **readUTF** lee del stream de entrada el número de bytes a recibir utilizando el método **readShort**, lee los bytes utilizando el método **read** y crea una instancia de la clase String utilizando codificación UTF-8.
    
    En Java una string puede tener una longitud máxima de 2,147,483,647 caracteres, sin embargo los métodos **writeUTF** y **readUTF** solo pueden enviar strings cuya codificación UTF-8 tenga una longitud máxima de 32,767 bytes.
    
      
    
    **La clase ByteBuffer**
    
    Ahora veremos cómo enviar de manera eficiente un conjunto de números punto flotante de 64 bits. 
    
    Supongamos que vamos a enviar cinco números punto flotante de 64 bits.  
    
    Primero "empacaremos" los números utilizando un objeto ByteBuffer.
    
    Cinco números punto flotante de 64 bits ocupan 5x8 bytes (64 bits=8 bytes). Entonces vamos a crear un objeto de tipo ByteBuffer con una capacidad de 40 bytes:
    
    ByteBuffer b = ByteBuffer.allocate(5*8);
    
    Utilizamos el método **putDouble** para agregar cinco números al objeto ByteBuffer:
    
    b.putDouble(1.1);
    b.putDouble(1.2);
    b.putDouble(1.3);
    b.putDouble(1.4);
    b.putDouble(1.5);
    
    Para enviar el "paquete" de números, convertimos el objeto ByteBuffer a un arreglo de bytes utilizando el método **array** de la clase ByteBuffer:
    
    byte[] a = b.array();
    
    Entonces enviamos el arreglo de bytes utilizando el método **write**:
    
      
    
    salida.write(a);
    
    Para terminar el programa cerramos la conexión con el servidor (al cerrar el socket se cierran también los streams asociados), en este caso vamos a poner un retardo de un segundo antes de cerrar la conexión, para permitir que el servidor tenga tiempo de recibir los datos:
    
    Thread.sleep(1000);
    conexion.close();
    
      
    
    ![No finalizado; Clase del día - 28/08/2024Arquitectura Cliente - S.... Seleccione para marcar como finalizado](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/i/completion-manual-n "No finalizado; Clase del día - 28/08/2024Arquitectura Cliente - S.... Seleccione para marcar como finalizado")
    
- #### Clase del día - 3/09/2024
    
    **Servidor.java**
    
    El programa **Servidor.java** va a esperar una conexión del cliente, entonces recibirá los datos que envía el cliente y a su vez, enviará datos al cliente.  
    
    Primeramente vamos a crear un socket servidor que va a abrir, en este caso, el puerto 50000:
    
    ServerSocket servidor = new ServerSocket(50000);
    
    Notar que en Windows, por razones de seguridad el firewall solicita al usuario administrador permiso para abrir este puerto.  
    
    Ahora invocamos el método **accept** de la clase ServerSocket.
    
    El método **accept** es bloqueante, lo que significa que el thread principal del programa quedará en estado de espera pasiva (una espera que no ocupa ciclos de CPU) hasta recibir una conexión del cliente. Cuando se recibe la conexión el método **accept** regresa un socket, en este caso vamos a declarar una variable de tipo Socket llamada "conexion":  
    
    Socket conexion = servidor.accept();
    
    Una vez establecida la conexión con el cliente, el servidor podrá enviar y recibir datos.
    
      
    
    Creamos un stream de salida y un stream de entrada:
    
      
    
    DataOutputStream salida = new DataOutputStream(conexion.getOutputStream());
    DataInputStream entrada = new DataInputStream(conexion.getInputStream());
    
    Recordemos que el cliente envía un entero de 32 bits, entonces el servidor deberá recibir este dato utilizando el método **readInt**:
    
      
    
    int n = entrada.readInt();
    System.out.println(n);
    
    Ahora el servidor recibe un número punto flotante de 64 bits utilizando el método **readDouble**:
    
      
    
    double x = entrada.readDouble();
    System.out.println(x);
    
    El servidor recibe una cadena de cuatro caracteres:
    
      
    
    byte[] buffer = new byte[4];
    read(entrada,buffer,0,4);
    System.out.println(new String(buffer,"UTF-8"));
    
    El servidor envía una cadena de cuatro caracteres:
    
      
    
    salida.write("HOLA".getBytes());
    
    Ahora vamos a recibir los cinco números punto flotante empacados en un arreglo de bytes.
    
    Recordemos que los cinco números punto flotante de 64 bits ocupan 40 bytes (5x8bytes).
    
    byte[] a = new byte[5*8];
    read(entrada,a,0,5*8);
    
    Una vez recibido el arreglo de bytes, lo convertimos a un objeto ByteBuffer utilizando el método **wrap** de la clase ByteBuffer:
    
      
    
    ByteBuffer b = ByteBuffer.wrap(a);
    
    Para extraer los números punto flotante, utilizamos el método **getDouble** de la clase ByteBuffer:
    
      
    
    for (int i = 0; i < 5; i++) System.out.println(b.getDouble());    
    
    Finalmente, cerramos la conexión con el cliente:
    
      
    
    conexion.close();
    
      
    
    **Un cliente con re-intentos de conexión**
    
      
    
    Como vimos anteriormente, para que el cliente se conecte al servidor es necesario que el servidor inicie su ejecución antes que el cliente, sin embargo para algunas aplicaciones el cliente debe esperar a que el servidor inicie su ejecución.
    
      
    
    Veamos ahora cómo implementar el re-intento de conexión cuando el servidor no está ejecutando.
    
      
    
    Socket conexion = null;
    for(;;)
      try
      {
        conexion = new Socket("localhost",50000);
        break;
      }
      catch (Exception e)
      {
        Thread.sleep(100);
      }
    
    Como podemos ver, cada vez que el cliente falla en establecer la conexión con el servidor, espera 100 milisegundos y vuelve a intentar la conexión. Cuando el cliente logra conectarse con el servidor entonces sale del ciclo for.
    
      
    
    ##### **Servidor multithread**
    
      
    
    Anteriormente vimos el programa **Servidor.java** el cual invoca el método **accept** para esperar una conexión del cliente, debido a que este método es bloqueante el programa queda en espera pasiva hasta que el cliente se conecta.  
    
    Cuando el servidor recibe una conexión, el método **accept** regresa un socket. Entonces el cliente y el servidor podrán intercambiar datos. Generalmente el servidor procesa los datos que recibe del cliente y al terminar vuelve a invocar el método **accept** para esperar otra conexión.
    
    Sin embargo, mientras el servidor procesa los datos que recibe del cliente, no puede recibir otra conexión. Para resolver este problema los servidores se construyen utilizando threads.
    
    En la clase de hoy veremos cómo construir un servidor multithread.
    
      
    
    **Ejecución paralela y ejecución concurrente**
    
    En las clases de Sistemas Operativos se explica que un thread (hilo) es la ejecución secuencial de las instrucciones de un programa.
    
    Un proceso puede crear uno o más threads (hilos de ejecución), los cuales van a ejecutar simultáneamente.
    
    Si la computadora tiene un CPU _dual core_, entonces el CPU podrá ejecutar en **paralelo** (al mismo tiempo) dos threads, si el CPU es _quad core_ entonces podrá ejecutar en paralelo cuatro threads, y así sucesivamente.
    
    Por otra parte, si un programa crea un número de threads mayor al número de procesadores físicos (_cores_) disponibles en la computadora, entonces los threads ejecutarán en forma **concurrente** (por turnos).
    
      
    
    **Programación multithread en Java**  
    
    Supongamos que tenemos una clase llamada **P**.
    
    Dentro de la clase **P** definimos una clase interior (_nested class_) llamada **Worker** la cual es subclase de la clase Thread:
    
    class P
    {
      static class Worker extends Thread
      {
        public void run()
        {
        }
      }
      public static void main(String[] args) throws Exception
      {
      }
    }
    
    Podemos ver que hemos incluido en la clase **Worker** un método público llamado **run** el cual no tiene parámetros ni regresa resultado.  
      
    
    **El método start**  
    
    Para iniciar la ejecución de un thread, debemos crear una instancia de la clase **Worker** e invocar el método **start** (este método se hereda de la clase Thread):
    
    Worker w = new Worker();
    w.start();
    
    Entonces se crea un hilo que inicia invocando el método **run** que hemos definido en la clase **Worker**.
    
    Un thread finaliza su ejecución cuando el método **run** termina. Cuando un thread finaliza, no puede volver a ejecutarse.
    
    **El método join  
    **
    
    Supongamos que el thread principal (el thread que invocó el método **start**) requiere esperar que el thread w termine su ejecución, entonces el thread principal deberá invocar el método **join**:  
    
    Worker w = new Worker();  
    w.start();  
    w.join();
    
    El método **join** queda en un estado de espera pasiva mientras el thread "w" se encuentra ejecutando, cuando el thread "w" termina, el método **join** regresa, entonces el thread principal continua su ejecución.  
    
    Ahora supongamos que el thread principal requiere crear dos threads y esperar a que terminen su ejecución. Entonces creamos dos instancias de la clase **Worker** e invocamos los métodos **start** y **join** para cada thread:
    
    Worker w1 = new Worker();  
    Worker w2 = new Worker();
    w1.start();  
    w2.start();  
    w1.join();  
    w2.join();  
    
    Cuando un thread (en este caso el thread principal) espera la terminación de uno o más threads para continuar su ejecución, se dice que se implementa una **barrera**. En este caso estamos implementando una barrera mediante dos métodos **join**.  
      
    
    **Servidor2.java**
    
    Ahora vamos a implementar un servidor de sockets multithread.  
    
    La idea es que el servidor multithread espere conexiones y para cada conexión cree un thread que procese los datos que envía el cliente.
    
      
    
    Vamos a invocar el método **accept** dentro de un ciclo, y para cada conexión vamos a crear un thread.
    
      
    
    class Servidor2
    {
      static class Worker extends Thread
      {
        Socket conexion;
        Worker(Socket conexion)
        {
          this.conexion = conexion;
        }
        public void run()
        {
        }
      }
      public static void main(String[] args) throws Exception
      {
        ServerSocket servidor = new ServerSocket(50000);
        for (;;)
        {
          Socket conexion = servidor.accept();
          Worker w = new Worker(conexion);
          w.start();
        }
      }
    }
    
      
    
    Este código será la base para otros programas que desarrollaremos en el curso.
    
      
    
    El constructor de la clase **Worker** pasa como parámetro el socket que crea el método **accept**, ya que el método **run** requiere el socket para recibir y enviar datos al cliente.
    
    Ahora agregaremos el siguiente código al método **run**:
    
    try  
    {  
      DataOutputStream salida = new DataOutputStream(conexion.getOutputStream());  
      DataInputStream entrada = new DataInputStream(conexion.getInputStream());  
      int n = entrada.readInt();  
      System.out.println(n);  
      double x = entrada.readDouble();  
      System.out.println(x);  
      byte[] buffer = new byte[4];  
      read(entrada,buffer,0,4);  
      System.out.println(new String(buffer,"UTF-8"));  
      salida.write("HOLA".getBytes());  
      byte[] a = new byte[5*8];  
      read(entrada,a,0,5*8);  
      ByteBuffer b = ByteBuffer.wrap(a);  
      for (int i = 0; i < 5; i++) System.out.println(b.getDouble());  
    }  
    catch(Exception e)  
    {  
      System.err.println(e.getMessage());  
    }  
    finally  
    {  
      try  
      {  
        conexion.close();  
      }  
      catch (Exception e2)  
      {  
        System.err.println(e2.getMessage());  
      }  
    }  
    
    Podemos ver en el programa **Servidor2.java** que el método **run** crea los streams que se utilizarán para enviar y recibir datos del cliente. Notar que el programa **Servidor2.java** es completamente compatible con el programa **Cliente.java**
    
    #####   
    
    **Nota**.
    
    El programa Servidor2.java abre el puerto 50000, sin embargo, un servidor HTTP abre el puerto 80.
    
    Debido a que los procesos en UNIX deben usar permisos administrativos para abrir los puertos menores a 1024, se recomienda **por razones de seguridad** que el servidor abra un puerto mayor que 1024, entonces se puede utilizar el comando iptables para mapear un puerto menor a 1024 a un puerto mayor a 1023.
    
    Por ejemplo, para mapear el puerto 80 (utilizado por el protocolo HTTP) al puerto 8080,  se puede ejecutar el siguiente comando:
    
    sudo iptables -A PREROUTING -t nat -i eth0 -p tcp --dport 80 -j REDIRECT --to-port 8080  
    
    Entonces el servidor puede ser ejecutado por un usuario no administrador; entonces el servidor abriría el puerto 8080 y el usuario se conectará al puerto 80.
    
      
    
    Reproducir Vídeo
    
      
    
    Reproducir Vídeo
    
      
    
      
    
    ##### Actividades individuales a realizar
    
      
    
    1. Compile los programas **Cliente.java** y **Servidor.java**
    2. Ejecute el programa **Servidor.java** en una ventana de comandos de Windows (o terminal de Linux o MacOS) y ejecute el programa **Cliente.java** en otra ventana de comandos de Windows (o terminal de Linux o MacOS).
    3. Modifique el programa cliente para que envíe 10000 números punto flotante utilizando el método writeDouble (enviar los números 1.0, 2.0, 3.0 ... 10000.0). Mida el tiempo que tarda el programa cliente en enviar los 10000 números, se sugiere utilizar el método System.currentTimeMillis()
    4. Modifique el programa servidor para que reciba los 10000 números que envía el programa cliente. Mida el tiempo que tarda el programa servidor en recibir los 10000 números.
    5. Ahora modifique el programa cliente para que envíe los 10000 números utilizando ByteBuffer. Mida el tiempo que tarda el programa cliente en enviar los 10000 números.
    6. Modifique el programa servidor para que reciba los 10000 números utilizando ByteBuffer. Mida el tiempo que tarda el programa servidor en recibir los 10000 números.
    7. ¿Qué resulta más eficiente, enviar los números de manera individual mediante writeDouble o enviarlos empacados mediante ByteBuffer?
    8. Compile el programa **Servidor2.java**
    9. Ejecute el programa **Servidor2****.java** en una ventana de comandos de Windows (o terminal de Linux o MacOS).
    10. Ejecute repetidamente el programa **Cliente.java** en otra ventana de comandos de Windows (o terminal de Linux o MacOS), como puede ver el servidor sigue en ejecución recibiendo las conexiones de los clientes y procesando los datos.
    11. Modifique el programa **Cliente.java** de manera que implemente re-intentos de conexión. Entonces ejecute el cliente en una ventana de comandos de Windows (o terminal de Linux o MacOS) y después ejecute el servidor en otra ventana de comandos de Windows (o terminal de Linux o MacOS), ahora el cliente deberá re-intentar la conexión sin terminar con error.
    
      
    
    ![No finalizado; Clase del día - 3/09/2024Servidor.javaEl programa&.... Seleccione para marcar como finalizado](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/i/completion-manual-n "No finalizado; Clase del día - 3/09/2024Servidor.javaEl programa&.... Seleccione para marcar como finalizado")
    
- #### Clase del día - 4/09/2024
    
      
    
    Un proxy es un servidor cuya función es recibir el tráfico TCP de un cliente y reenviarlo a un servidor final, así mismo, recibir el tráfico TCP del servidor y reenviarlo al cliente.  
    
    Existen diferentes tipos de proxies, entre otros:
    
    **Proxy HTTP/HTTPS**. Permite monitorear y filtrar las peticiones que envía el cliente al servidor HTTP, así mismo, permite monitorear y filtrar las respuestas del servidor.
    
    **Proxy inverso**. Recibe el tráfico de red de un cliente y lo distribuye entre diferentes servidores, de acuerdo a una configuración específica, por ejemplo, una configuración de balance de carga.
    
    Un proxy inverso permite ocultar la dirección IP de los servidores, almacenar el contenido estático (imágenes, archivos JS o CSS) y centralizar la gestión de la comunicación SSL (utilizando un solo certificado digital en el proxy).
    
    **Proxy transparente**. Redirige el tráfico TCP sin que el cliente se de cuenta que hay un proxy entre el cliente y el servidor. Los proxies transparentes reenvían el tráfico TCP sin considerar un protocolo específico sobre TCP (como sería HTTP, SMTP, FTP, etc.).
    
      
    
    **Arquitectura de un proxy transparente**
    
    Un proxy transparente consta de un servidor y un cliente.
    
    Cuando el servidor del proxy recibe una conexión del cliente, el cliente del proxy se conecta al servidor.
    
    El servidor del proxy recibe tráfico de red del cliente y lo envía al servidor, así mismo, el cliente del proxy recibe tráfico de red del servidor y lo envía al cliente.
    
      
    
      
    **Implementación de un proxy transparente en Java  
    **  
    Vamos a implementar un proxy transparente mediante un servidor TCP multithread.  
      
    Cuando el servidor del proxy recibe la conexión del cliente, crea un thread de tipo Worker_1, éste thread crea un segundo thread de tipo Worker_2.  
      
    El thread de tipo Worker_2 se conecta al servidor remoto y se encarga de reenviar el tráfico TCP del servidor remoto al cliente.  
      
    El thread de tipo Worker_1 se encarga de reenviar el tráfico TCP del cliente al servidor remoto.  
      
    Debido a que un proxy transparente no implementa un protocolo específico sobre TCP, es necesario que el reenvío del tráfico TCP del cliente al servidor se pueda realizar en paralelo al reenvío del tráfico TCP del servidor al cliente. Por esta razón, es necesario crear dos threads que reenvíen el tráfico TCP de manera independiente.  
      
    El código del proxy transparente es el siguiente:  
      
    
    /*
      Proxy.java
      Carlos Pineda G. 2024
    */
    import java.io.InputStream;
    import java.io.OutputStream;
    import java.io.IOException;
    import java.net.Socket;
    import java.net.ServerSocket;
    class Proxy
    {
      static String host_remoto;
      static int puerto_remoto;
      static int puerto_local;
      static class Worker_1 extends Thread
      {
        Socket cliente_1,cliente_2;
        Worker_1(Socket cliente_1)
        {
          this.cliente_1 = cliente_1;
        }
        public void run()
        {
          try
          {
            // se conecta al host remoto
            cliente_2 = new Socket(host_remoto,puerto_remoto);
            // thread que dirige el tráfico del host remoto al cliente
            new Worker_2(cliente_1,cliente_2).start();
            InputStream entrada_1 = cliente_1.getInputStream();
            OutputStream salida_2 = cliente_2.getOutputStream();
            byte[] buffer = new byte[1024];
            int n;
            while((n = entrada_1.read(buffer)) != -1)
            {
              salida_2.write(buffer,0,n);
              salida_2.flush();
            } 
          }
          catch (IOException e)
          {
          }
          finally
          {
            try
            {
              if (cliente_1 != null) cliente_1.close();
              if (cliente_2 != null) cliente_2.close();
            }
            catch (IOException e2)
            {
              e2.printStackTrace();
            }
          }
        }
      }
      static class Worker_2 extends Thread
      {
        Socket cliente_1,cliente_2;
        Worker_2(Socket cliente_1,Socket cliente_2)
        {
          this.cliente_1 = cliente_1;
          this.cliente_2 = cliente_2;
        }
        public void run()
        {
          try
          {
            InputStream entrada_2 = cliente_2.getInputStream();
            OutputStream salida_1 = cliente_1.getOutputStream();
            byte[] buffer = new byte[4096];
            int n;
            while((n = entrada_2.read(buffer)) != -1)
            {
              salida_1.write(buffer,0,n);
              salida_1.flush();
            } 
          }
          catch (IOException e)
          {
          }
          finally
          {
            try
            {
              if (cliente_1 != null) cliente_1.close();
              if (cliente_2 != null) cliente_2.close();
            }
            catch (IOException e2)
            {
              e2.printStackTrace();
            }
          }
        }
      }
      public static void main(String[] args) throws Exception
      {
        if (args.length != 3)
        { 
          System.err.println("Uso:\nProxy <host-remoto> <puerto-remoto> <puerto-local>");
          System.exit(1);
        }
        host_remoto = args[0];
        puerto_remoto = Integer.parseInt(args[1]);
        puerto_local = Integer.parseInt(args[2]);
        System.out.println("host_remoto: " + host_remoto + ", puerto_remoto: " + puerto_remoto + ", puerto_local: " + puerto_local);
        ServerSocket ss = new ServerSocket(puerto_local);
        for(;;)
        {
          // espera una conexión del cliente
          Socket cliente_1 = ss.accept();
    
          // thread que dirige el tráfico del cliente al host remoto
          new Worker_1(cliente_1).start();
        }
      }
    }  
    
      
    
    #### Actividades individuales a realizar
    
      
    
    **Creación de una máquina virtual con Ubuntu**  
    
      
    Ingresar al portal de Azure en la siguiente URL:
    
    [https://azure.microsoft.com/es-mx/features/azure-portal/](https://azure.microsoft.com/es-mx/features/azure-portal/)  
      
    1. Dar clic al botón "Iniciar sesión".  
      
    2. En el portal de Azure seleccionar "Máquinas virtuales".  
      
    3. Seleccionar la opción "+Crear".  
      
    4. Seleccionar la opción "Máquina virtual en Azure"  
      
    5. Seleccionar el grupo de recursos o crear uno nuevo. Un grupo de recursos es similar a una carpeta donde se pueden colocar los diferentes recursos de nube que se crean en Azure.  
      
    6. Ingresar el nombre de la máquina virtual.  
      
    7. Seleccionar la región donde se creará la máquina virtual. Notar que el costo de la máquina virtual depende de la región. Es recomendable crear la máquina virtual en una región cercana de manera que la comunicación con la máquina virtual sea más rápida.  
    
    7.1 En el campo "Tipo de seguridad" seleccionar "Estándar".
    
    8. Seleccionar la imagen, en este caso vamos a seleccionar Ubuntu Server 20.  
      
    9. En el campo "Tamaño" dar clic en "Ver todos los tamaños", en este caso vamos a seleccionar una máquina virtual con 1 GB de memoria RAM (Tamaño de VM B1s). Dar clic en el botón "Seleccionar".  
      
    10. En tipo de autenticación seleccionamos "Contraseña".  
      
    11. Ingresamos el nombre del usuario, por ejemplo: ubuntu  
      
    12. Ingresamos la contraseña y confirmamos la contraseña. La contraseña debe tener al menos 12 caracteres, debe al menos una letra minúscula, una letra mayúscula, un dígito y un carácter especial.  
      
    13. En las "Reglas de puerto de entrada" se deberá dejar abierto el puerto 22 para utilizar SSH (la terminal de secure shell).  
      
    14. Dar clic en el botón "Siguiente: Discos>"  
      
    15. Seleccionar el tipo de disco de sistema operativo, en este caso vamos a seleccionar HDD estándar.  
      
    16. Dar clic en el botón "Siguiente: Redes>"
    
    Por default se creará una red virtual y la máquina virtual se conectará a esta red virtual. También se creará una IP pública.  
      
    17. Dar clic en el botón "Siguiente: Administración>"  
      
    18. Dar clic en el botón "Siguiente: Supervisión>"  
      
    19. En el campo "Diagnóstico de arranque" seleccionar "Deshabilitar".  
      
    20. Dar clic en el botón "Revisar y crear".  
      
    21. Dar clic en el botón "Crear".  
      
    22. Dar clic a la campana de notificaciones (barra superior de la pantalla) para verificar que la maquina virtual se haya creado.  
      
    23. Dar clic en el botón "Ir al recurso". En la página se puede ver la dirección IP pública de la máquina virtual. Esta dirección puede cambiar cada vez que se apague y se encienda la máquina virtual.  
      
    24. Para conectarnos a la máquina virtual vamos a utilizar el programa **ssh** disponible en Windows, Linux y MacOS.
    
    25. En una ventana de comandos de Windows o una terminal de Linux o MacOS ejecutar el programa **ssh** así:
    
    ssh _usuario_@_ip-máquina-virtual_
    
    Donde _usuario_ es el usuario que ingresamos en el paso 11, _ip-máquina-virtual_ es la ip pública de la máquina virtual.
    
    26. Para enviar o recibir archivos de la máquina virtual, se puede utilizar el programa **sftp** disponible en Windows, Linux y MacOS. Se ejecuta así:
    
    sftp _usuario_@_ip-máquina-virtual_
    
    Para enviar archivos se utiliza el comando **put** y para recibir archivos se utiliza el comando **get**.
    
    Para mayor información sobre sftp ver:
    
    [https://www.digitalocean.com/community/tutorials/how-to-use-sftp-to-securely-transfer-files-with-a-remote-server-es](https://www.digitalocean.com/community/tutorials/how-to-use-sftp-to-securely-transfer-files-with-a-remote-server-es)  
      
      
    **Abrir un puerto de entrada**
    
    Para que los programas que ejecutan en la máquina virtual pueda recibir conexiones a través de un determinado puerto, es necesario crear una regla de entrada para el puerto.
    
    Por ejemplo, vamos a abrir el puerto 50000 en la máquina virtual que acabamos de crear:
    
    1. Entrar al portal de Azure
    2. Seleccionar "Máquinas virtuales".
    3. Seleccionar la máquina virtual.
    4. Dar clic en "Configuración de red".
    5. Dar clic en el botón "+Crear ACL del puerto".
    6. Seleccionar "Regla de puerto de entrada".
    7. En el campo "Intervalos de puertos de destino" ingresar: 50000  
        
    8. Seleccionar el protocolo: TCP
    9. En el campo "Nombre" ingresar un nombre para la regla, por ejemplo: Puerto_50000
    10. Dar clic en el botón "Aceptar".
    
      
    
    **Detener una máquina virtual**  
    
    Cuando una máquina virtual no se utiliza es conveniente detenerla con el fin de reducir el costo. Para detener una máquina virtual:  
      
    1. Dar clic en la opción "Detener" en el portal de Azure.  
    2. Cuando se pregunta ¿Desea detener ...? dar clic en el botón "Sí".  
      
    Esperar a que el estado de la máquina virtual sea "Desasignada".  
      
    **Encender una máquina virtual  
    **  
    Para encender una máquina virtual  
      
    1. Seleccionar la opción "Iniciar" en la página de la máquina virtual dentro del portal de Azure.  
      
    Esperar a que el estado de la máquina virtual sea "En ejecución".  
      
    **Eliminar una máquina virtual  
    **  
    Para eliminar una máquina virtual:  
      
    1. Seleccionar la opción "Eliminar" en la página de la máquina virtual dentro del portal de Azure.  
    
    2. Seleccionar los recursos a eliminar (Disco de SO, interfaces de red y direcciones IP públicas.
    
    3. Aceptar la advertencia que dice que se eliminarán los recursos seleccionados.
    
    4. Dar clic en el botón "Eliminar".
    
    **Restablecer la contraseña de una máquina virtual  
    **  
    En caso de no recordar la contraseña de un usuario de una máquina virtual, se puede realizar el siguiente procedimiento:  
      
    
    1. Ejecutar el portal de Azure.
    2. Seleccionar la opción "Máquinas virtuales" (para restablecer la contraseña la máquina virtual debe estar encendida).
    3. Seleccionar la máquina virtual a modificar.
    4. En el menú que aparece a la izquierda de la pantalla seleccionar la opción "Restablecer contraseña".
    5. En el menú "Modo" seleccionar "Restablecer contraseña".
    6. En el campo "Nombre de usuario" ingresar el usuario.
    7. En el campo "Contraseña" ingresar la nueva contraseña para el usuario.
    8. En el campo "Confirmar contraseña" repetir la nueva contraseña.
    9. Dar clic en el ícono "Actualizar".
    
      
    
    Reproducir Vídeo
    
      
    
    Reproducir Vídeo
    
      
    
      
    
    ![No finalizado; Clase del día - 4/09/2024Un proxy es un servidor c.... Seleccione para marcar como finalizado](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/i/completion-manual-n "No finalizado; Clase del día - 4/09/2024Un proxy es un servidor c.... Seleccione para marcar como finalizado")
    
- #### Clase del día - 6/09/2024
    
      
    
    #### Sincronización del acceso a memoria
    
      
    
    **Operaciones de lectura y escritura**
    
    Los threads dentro de un proceso se comunican entre sí utilizando la memoria. Las operaciones que se realizan sobre la memoria son la lectura y escritura de variables (localidades de memoria).
    
    Para que un thread pueda leer los datos que escribe otro thread en la memoria, es necesario ordenar las operaciones de lectura y escritura que realizan los threads.
    
    Supongamos que tenemos dos threads, el thread T1 y el thread T2.
    
    Si el thread T2 escribe a una variable y posteriormente el thread T1 lee la variable, el thread T1 tendrá el valor que escribió el thread T2.
    

    
    **Orden escritura-escritura**  
    
    Ahora supongamos que los threads T1 y T2 escriben al mismo tiempo una variable y posteriormente los threads leen al mismo tiempo la misma variable. ¿Qué valores leyeron los threads?
    

    
    Evidentemente no es posible garantizar que el thread T1 haya leído el valor que escribió el thread T2 o que haya leído el valor que escribió el mismo thread T1. 
    
    Igualmente, no es posible garantizar que el thread T2 haya leído el valor que escribió el thread T1 o que el thread T1 haya el valor que escribió el mismo thread T2.
    
    Entonces, para garantizar que un thread lee el valor de una variable escrito por otro thread, es necesario ordenar las operaciones de escritura y de lectura que realizan los threads.
    
    Ahora supongamos que el thread T1 espera a que el thread T2 escriba la variable, entonces después el thread T1 escribe a la variable.
    

    
    En este caso, el valor que leen los threads T1 Y T2 es el valor que escribió el thread T1.
    
    Notar que dos o más threads pueden leer simultáneamente una variable.
    
    **Orden escritura-lectura**
    
    Ahora supongamos que el thread T1 lee la variable y posteriormente el thread T2 escribe la variable ¿qué valor leyó el thread T1?
    

    
      
    
    Para que el thread T1 pueda leer el valor que escribe el thread T2, es necesario ordenar las operaciones de escritura y lectura.
    
    Para garantizar que el thread T1 lea el valor escrito por el thread T2, el thread T1 debe esperar a que el thread T2 escriba la variable.
    

    
      
    
    **Si** **dos o más threads acceden a una misma variable, y al menos uno de los threads escribe la variable**, entonces es necesario sincronizar el acceso de los threads a la variable.  
    
    Sincronizar el acceso de los threads significa ordenar las operaciones de escritura y de lectura que realizan los threads.
    
      
    
    **La instrucción synchronized**
    
      
    
    Para ordenar las lecturas y escrituras que realizan los threads en Java, se utiliza la instrucción **synchronized**.
    
      
    
    synchronized(_objeto_)  
    {  
      _instrucciones_  
    }  
    
      
    
    Debemos recordar que en Java todos los objetos tienen un lock asociado.
    
      
    
    En la clase de Sistemas Operativos se explica que un _lock_ (o cerrojo) es un mecanismo que permite limitar el acceso a un recurso compartido por varios procesos o threads, por ejemplo, una variable, un archivo, una impresora. etc. 
    
      
    
    A la capacidad que tiene un sistema de controlar el acceso a recursos compartidos se le conoce como **exclusión mutua**.
    
      
    
    La instrucción **synchronized** funciona de la siguiente manera:
    
    - Primero se verifica si el lock del _objeto_ está bloqueado, si el lock está bloqueado entonces el thread espera a que el lock se desbloquee.
    
    - Por otra parte, si el lock está desbloqueado entonces el thread lo bloquea (se dice que "el thread adquiere el lock") y ejecuta las instrucciones dentro del bloque.
    
    - Al terminar de ejecutar las instrucciones el thread desbloquea el lock (se dice que "el thread libera el lock"), entonces el sistema operativo notifica a alguno de los threads que se encuentran esperando el lock  para que adquiera el lock y ejecute las instrucciones dentro del bloque.
    
    - Al terminar de ejecutar las instrucciones, el thread desbloquea el lock  y nuevamente el sistema operativo notifica a alguno de los threads que esperan.
    
      
    
    Como podemos ver, la instrucción **synchronized** evita que dos o más threads ejecuten simultáneamente un bloque de instrucciones. Al bloque de instrucciones que solo puede ser ejecutado por un thread se le llama **sección crítica**.
    
      
    
    Veamos un ejemplo.
    
      
    
    Supongamos que tenemos dos threads que incrementan una variable estática llamada "n" dentro de un ciclo for.
    
      
    
    La variable estática "n" es "global" a todas las instancias de la clase, por tanto los threads pueden leer y escribir esta variable.  
    
      
    
    class A extends Thread  
    {  
      static long n;  
      public void run()  
      {  
        for (int i = 0; i < 100000; i++)  
            n++;  
      }  
      public static void main(String[] args) throws Exception  
      {  
        A t1 = new A();  
        A t2 = new A();  
        t1.start();  
        t2.start();  
        t1.join();  
        t2.join();  
        System.out.println(n);  
      }  
    }  
    
      
    
    En este caso, la clase principal A es subclase de la clase Thread, por tanto hereda los métodos run, start y join (entre otros).
    
      
    
    El programa debería desplegar 200000 ya que cada thread incrementa 100,000 veces la variable "n".
    
      
    
    ¿Por qué despliega un número menor a 200,000?
    
    ¿Por qué cada vez que se ejecuta el programa despliega un número diferente?  
    
      
    
    La instrucción **n++** se compone de tres operaciones:  
    
    1. Copiar el valor de la variable **n** a un registro del procesador.
    2. Incrementar el valor del registro.
    3. Escribir el valor del registro a la variable **n**.
    
    Debido a que los threads **t1** y **t2** ejecutan en paralelo en una computadora con dos o más núcleos, el thread **t1** puede leer y escribir la variable **n** al mismo tiempo que el thread **t2**:  
    

    
    Dado que la lectura que realiza **t1** no está ordenada con respecto a la escritura que hace **t2** y que la lectura que realiza **t2** no está ordenada con respecto a la escritura que hace **t1**, es posible que no se escriba algún incremento en la variable **n** lo que produce un valor final menor a 200,000.
    
    Entonces debemos impedir que ambos threads ejecuten al mismo tiempo la instrucción n++. Justamente esta instrucción es la sección crítica.  
    
    Para resolver este problema vamos a ejecutar la instrucción n++ dentro de una instrucción **synchronized**; notar que utilizamos el objeto "obj" para sincronizar los threads:
    
    Entonces el código del programa queda de la siguiente manera:  
    
    class A extends Thread  
    {  
      static long n;  
      static Object obj = new Object();  
      public void run()  
      {  
        for (int i = 0; i < 100000; i++)  
          synchronized(obj)  
          {  
            n++;  
          }  
      }  
      public static void main(String[] args) throws Exception  
      {  
        A t1 = new A();  
        A t2 = new A();  
        t1.start();  
        t2.start();  
        t1.join();  
        t2.join();  
        System.out.println(n);  
      }  
    }
    
    Al ejecutar varias veces el programa anterior podemos ver que el valor final de la variable **n** siempre es 200,000, debido a que ahora las operaciones de lectura y escritura se ejecutan en el orden correcto:
    

    
      
    
    Si bien es cierto que es necesario sincronizar los threads para que el programa funcione correctamente, la sincronización hace más lento el programa, ya que obliga a que ciertas partes del programa se ejecuten en serie (una tras otra) y no en paralelo (al mismo tiempo).
    
      
    
    **Sincronización de threads**
    
    **El método wait**
    
    Cuando un thread ejecuta el método wait() de la clase Object, el thread entra en un estado de espera pasiva (el thread no consume ciclos de CPU mientras espera).
    
    El método wait() debe utilizarse dentro de una instrucción synchronized.
    
    En Java cada lock tiene una cola de espera, de manera que cada thread que ejecuta el método wait(), se forma en la cola de espera del lock asociado a la instrucción synchronized.  
      
    Una vez que el thread queda en estado de espera pasiva, se libera el lock. Cuando el thread "despierta" vuelve a adquirir el lock.  
      
    El método wait() puede producir la excepción InterruptedException, por tanto es necesario colocar el método wait() dentro de un bloque try o bien, indicar que el método actual puede producir dicha excepción agregando la cláusula throws al método que invoca el método wait().  
    
    **  
    Los métodos notify y notifyAll  
    **  
    Para "depertar" un thread que se encuentra en espera pasiva, otro thread deberá invocar el método notify() o el método notifyAll().  
    
    El método notify() "despierta" el primer thread que se encuentra en la cola de espera del lock, y en el segundo caso, el método notifyAll() "despierta" todos los threads que se encuentran en la cola de espera del lock.  
    
    Al igual que el método wait(), los métodos notify() y notifyAll() deben ejecutar dentro de una instrucción **synchronized.**
    
    Debido a que los métodos wait(), notify() y notifyAll() son métodos de la clase Object, se heredan a todas las clases en Java.
    
      
    
    El siguiente programa muestra un ejemplo del uso de wait() y notify(). En este caso se crea un thread que entra en modo de espera pasiva invocando el método wait(), entonces el thread principal "despierta" el thread invocando el método notify().
    
    class Notificacion  
    {  
      static Object obj = new Object();  static class Worker extends Thread  {    public void run()    {      try      {        synchronized(obj)        {          System.out.println("antes de wait");          obj.wait();          System.out.println("después de wait");        }      }      catch(Exception e)      {        e.printStackTrace();      }    }  }  public static void main(String[] args) throws Exception  {    Worker w = new Worker();    w.start();    Thread.sleep(1000);    synchronized(obj)    {      System.out.println("antes de notify");      obj.notify();      System.out.println("después de notify");    }  }}
    
      
    
    #### Actividades individuales a realizar
    
      
    
    En esta actividad vamos a ver cómo crear una máquina virtual con Windows, cómo conectarse a la máquina virtual y cómo transferir archivos.
    
      
    
    Es muy importante que cada alumno elimine la máquina virtual una vez haya terminado de utilizarla, ya que mantener encendida una máquina virtual genera costo, lo que representa una disminución en el crédito que tiene el alumno como parte del programa Azure for Students.  
    
      
    
    **Creación de una máquina virtual con Windows**
    
    1. En el portal de Azure seleccionar "Máquinas virtuales".
    
    2. Seleccionar las opciones "+Crear" y "+Máquina virtual".
    
    3. Seleccionar el grupo de recursos o crear uno nuevo.
    
    4. Ingresar el nombre de la máquina virtual.
    
    5. Seleccionar la región donde se creará la máquina virtual. Notar que el costo de la máquina virtual depende de la región.
    
    6. Seleccionar la imagen, en este caso vamos a seleccionar Windows Server 2012.
    
    6.1 En el campo "Tipo de seguridad" seleccionar "Estándar".
    
    7. Seleccionar el tamaño de la máquina virtual, en este caso vamos a seleccionar una máquina virtual con al menos 2 GB de memoria.
    
    8. Ingresar el nombre del usuario administrador y la contraseña.
    
    9. En las "Reglas de puerto de entrada" se deberá dejar abierto el puerto 3389 para utilizar Remote Desktop Protocol (RDP).
    
    10. Dar clic en el botón "Siguiente: Discos>"
    
    11. Seleccionar el tipo de disco de sistema operativo, en este caso vamos a seleccionar HDD estándar.
    
    12. Dar clic en el botón "Siguiente: Redes>"
    
    13. Dar clic en el botón "Siguiente: Administración>"  
    
    14. En el campo "Diagnóstico de arranque" seleccionar "Deshabilitar".
    
    15. Dar clic en el botón "Revisar y crear".
    
    16. Dar clic en el botón "Crear".
    
    17. Dar clic a la campana de notificaciones para verificar que la máquina virtual se haya creado.
    
    18. Dar clic en el botón "Ir al recurso".
    
    19. Seleccionar la opción "Conectar". Seleccionar "RDP".  
    
    20. Dar clic en el botón "Descargar archivo RDP".
    
    21. Ejecutar "cmd" en la computadora local.
    
    22. Vamos a crear un directorio en la computadora local. La máquina virtual recién creada va a ver este directorio como un disco lógico. Por ejemplo, el directorio se llamará "prueba". Ejecutar el siguiente comando en la ventana de Símbolo del sistema:
    
    mkdir prueba
    
    23. Ahora vamos a crear un disco lógico como alias del directorio creado. Ejecutar el siguiente comando:  
    
    subst f: prueba
    
    Podemos ver que el disco lógico aparece en el explorador de archivos de Windows.  
    
    24. Buscar el archivo de conexión en la carpeta de descargas (un archivo con el nombre de la máquina virtual y la extensión ".rdp").
    
    25. Dar clic derecho al archivo de conexión y seleccionar "Modificar".
    
    26. Seleccionar la pestaña "Recursos locales".
    
    27. Dar clic en el botón "Mas..."
    
    28. Abrir la sección "Unidades".
    
    29. Marcar la casilla "Windows (F:)"
    
    30. Dar clic en el botón "Aceptar".
    
    31. Dar clic en el botón "Conectar" en la pantalla de advertencia.
    
      
    
    32. Ingresar el nombre de usuario administrador y la contraseña.
    
    33. Dar clic en el botón "Sí" en la ventana de advertencia. Entonces se abrirá una ventana de escritorio remoto, la cual nos dará acceso al escritorio de la máquina virtual.
    
    34. Configurar los parámetros de privacidad y dar clic en el botón "Accept".
    
    35. En la ventana "Networks" dar clic en el botón "No".
    
    36. Para ver el disco lógico creado en el paso 23, abrir el explorador de Windows de la máquina virtual. Entonces para enviar archivos desde la computadora local a la máquina virtual se deberá colocar los archivos en el directorio creado en el paso 22, y para enviar archivos desde la máquina virtual a la computadora local se deberá colocar los archivos en el disco F de la máquina virtual.
    
    **Nota**. El teclado local podría no coincidir con la configuración del teclado de la maquina remota.  
    
    37. Para desconectarse de la máquina virtual, dar clic en el botón "X" del escritorio remoto. Notar que al cerrar el escritorio remoto la máquina virtual sigue ejecutando.
    
      
    
    Reproducir Vídeo
    
      
    
      
      
    
- #### Clase del día - 10/09/2024
    
      
    
    La clase de hoy vamos a construir un servidor HTTP utilizando como base el servidor multi-thread que vimos anteriormente.
    
      
    
    **¿Qué es un servidor HTTP?**
    
    Un servidor HTTP es un servidor que recibe peticiones HTTP a través de una conexión TCP.
    
    En general, los servidores HTTP son **multi-thread**, de tal manera que el servidor creará un thread cada vez que un cliente se conecta, de esta forma cada thread se encarga de recibir la petición y enviar la respuesta al cliente.
    
    Por default los servidores HTTP reciben conexiones a través del puerto 80, sin embargo un servidor HTTP puede utilizar otro puerto, por ejemplo el puerto 8080.
    
    El protocolo HTTP define las operaciones que el servidor HTTP puede realizar cuando recibe una petición, a estas operaciones se les conoce como "métodos".
    
    Los métodos HTTP más utilizados son: GET, POST, PUT, DELETE y HEAD.  
    
    El método GET es utilizado por los navegadores (_browsers_) para solicitar un recurso o contenido al servidor HTTP.  
    
    Si el recurso existe, el servidor regresa al navegador como mínimo lo siguiente: el código 200 (OK), el tipo del recurso, la longitud del recurso y el contenido.
    
    Si el recurso no existe, el servidor regresa al navegador el código 404 (Not Found).  
    
      
    
    **[ServidorHTTP.java](https://m4gm.com/moodle/mod/resource/view.php?id=2253 "ServidorHTTP.java")**
    
    Para implementar el servidor HTTP utilizaremos el código del servidor multithread que vimos la clase anterior.
    
    Cada vez que un cliente (navegador) se conecte al servidor HTTP, se creará un thread el cual recibirá como parámetro el socket cliente.
    
    Primeramente, escribimos las siguientes instrucciones en el método run():
    
    BufferedReader entrada = new BufferedReader(new InputStreamReader(conexion.getInputStream()));  
    PrintWriter salida = new PrintWriter(conexion.getOutputStream());
    
    En este caso no vamos a utilizar las clases DataInputStream y DataOutpuStream debido a que necesitamos los métodos readLine() y println() los cuales están disponibles en las clases BufferedReader y PrintWriter, respectivamente.
    
    Notar que creamos la instancia de BufferedReader a partir del InputStream disponible en el socket, así mismo, creamos la instancia de PrintWriter a partir del OutputStream disponible en el socket.
    
    Ahora vamos a recibir la petición mediante el método readLine().
    
    Cada línea en el protocolo HTTP termina con un _carriage return_ (código ASCII 13) y _line feed_ (código ASCII 10) o cambio de línea, por tanto para leer la petición utilizamos el método readline().
    
    String req= entrada.readLine();  
    System.out.println(req);
    
    Además de la petición, el navegador envía encabezados; cada encabezado termina con _carriage return_  y _line feed)._
    
    Después de los encabezados  el navegador envía una línea en blanco (_carriage return_  y _line feed)_.
    
    Podemos leer los encabezados mediante el siguiente código:
    
    for (;;)  
    {  
      String encabezado= entrada.readLine();  
      System.out.println(encabezado);  
      if (encabezado.equals("")) break;  
    }  
    
    Supongamos que la URL que vamos a escribir en el navegador es la siguiente:  
    
    http://localhost/hola
    
    En este caso, el servidor deberá estar escuchando el puerto 80 (el puerto default para HTTP).
    
    Para que el servidor HTTP procese esta petición, podemos utilizar el método startsWith() de la clase String:
    
    if (req.startsWith("GET /hola "))
    {
      String contenido = "<html><button onclick='alert(\"OK\")'>Aceptar</button></html>";
      salida.println("HTTP/1.1 200 OK");
      salida.println("Content-Type: text/html; charset=utf-8");  
      salida.println("Content-Length: "+contenido.length());
      salida.println();
      salida.println(contenido);
      salida.flush();
    }  
    
    Notar que es necesario separar los encabezados del contenido, mediante una línea en blanco; en éste caso el contenido es de tipo texto.
    
    La forma general del encabezado Content-Type es la siguiente:
    
    Content-Type: tipo/subtipo
    
    Donde tipo es el tipo del contenido (por ejemplo, text) y subtipo es una especificación del tipo (por ejemplo: html).
    
    A la cadena tipo/subtipo se le llama **tipo mime** (_Multipurpose Internet Mail Extensions_). Los servidores pueden obtener el tipo mime de un archivo a partir de la extensión del archivo. Ver: [Lista completa de tipos MIME](https://developer.mozilla.org/es/docs/Web/HTTP/Basics_of_HTTP/MIME_types/Common_types)
    
    Por default, el protocolo HTTP/1.1 deja abierta la conexión entre el cliente y el servidor. En este caso, el servidor envió al navegador el encabezado “Connection: close”, indicando que la conexión se cerrará después de enviar la respuesta.
    
    En código anterior, el servidor HTTP regresa al navegador un texto html el cual creará un botón; cuando el usuario de clic al botón, se desplegará en el navegador una ventana con el letrero "OK".
    
      
    
    **Respuesta 404 File Not Found  
    **  
    Si la petición enviada por el navegador no es "GET /hola" podemos regresar al navegador el código de error 404 indicando que no se encontró el recurso:  
    
      else  
      {  
        salida.println("HTTP/1.1 404 File Not Found");  
        salida.flush();  
      }  
    
    Si deseamos que el navegador reciba un mensaje de error, se puede regresar el mensaje tal como lo hicimos anteriormente pero ahora regresar un código entre 400 y 499 indicando una condición de error, ver: [Códigos de estado de respuesta HTTP](https://developer.mozilla.org/es/docs/Web/HTTP/Status).
    
      
    
    **Los encabezados Server y Date**
    
    Opcionalmente el servidor HTTP podría enviar al navegador los siguientes encabezados, indicando el nombre del servidor y la fecha:  
    
        salida.println("Server: [ServidorHTTP.java](https://m4gm.com/moodle/mod/resource/view.php?id=2253 "ServidorHTTP.java")");  
        salida.println("Date: " + new Date());
    
    **  
    El encabezado Last-Modified  
    **  
    Un servidor HTTP puede regresar al navegador una variedad de contenidos, por ejemplo, una página web, una imagen, un archivo, etc.  
      
    En general, estos recursos no se modifican con frecuencia en el servidor, por esta razón es conveniente que el navegador guarde una copia del recurso y solo reciba una actualización del recurso cuando éste ha sido modificado en el servidor.  
      
    Los navegadores almacenan copias de los recursos en una cache.  
      
    Almacenar los recursos en la cache tiene muchas ventajas, entre otras: mejora la velocidad de carga, reduce el ancho de banda utilizado, ahorra energía en el cliente (esto es especialmente útil en dispositivos móviles), mejora la experiencia del usuario y reduce la carga en el servidor.  
      
    Para que el navegador guarde un recurso en la cache, el servidor envía al navegador la respuesta "HTTP/1.1 200 OK", el encabezado "Last-Modified" y el recurso solicitado. El encabezado, "Last-Modified" le dice al navegador la fecha (en formato RFC1123) de la última modificación del recurso.  
      
    Por ejemplo, la respuesta:  
      
    
    HTTP/1.1 200 OK  
    Last-Modified:  Fri, 25 Aug 2023 21:00:00 GMT
    
      
    Le dice al navegador que guarde el recurso en la cache indicando así mismo la fecha de la última modificación, en este caso el viernes 25 de agosto de 2023 a las 21 horas tiempo GMT.  
      
    Cada vez que el navegador solicita el recurso al servidor, el navegador agregará el siguiente encabezado a la petición:  
      
    
    If-Modified-Since: Fri, 25 Aug 2023 21:00:00 GMT
    
      
    Esto le dice al servidor que el navegador tiene una copia del recurso solicitado, indicando la fecha de última modificación (la cual le envío el servidor previamente utilizando el encabezado "Last-Modified").  
      
    Entonces el servidor deberá comparar la fecha enviada por el navegador y la fecha de la última modificación del recurso en el servidor, si la primera fecha es menor a la segunda fecha, entonces el servidor deberá enviar al navegador la respuesta "HTTP/1.1 200 OK", el encabezado "Last-Modified" incluyendo la nueva fecha de modificación y el recurso solicitado. De otra forma, el servidor solo enviará al navegador la siguiente respuesta:  
      
    
    HTTP/1.1 304 Not Modified
    
      
    Como podemos ver, el navegador recibe la actualización del recurso solo si el recurso se modificó después de que el navegador lo recibió por última vez.  
      
    ¿Es conveniente guardar cualquier respuesta en la cache?  
      
    No siempre, ya que en algunos casos las respuestas serán distintas en cada petición, por ejemplo, los datos obtenidos de una base de datos.  
      
    En este caso el servidor no regresará al navegador el encabezado "Last-Modified" por tanto el navegador no guardará en la cache la respuesta ni enviará el encabezado "If-Modified-Since" en cada petición ulterior.  
    **  
      
    El encabezado Cache-Control  
    **  
    El encabezado Cache-Control es enviado por el servidor para controlar la cache del navegador.  
    Las opciones más comunes del encabezado Cache-Control son las siguientes:  
      
    
    - **public** El contenido puede almacenarse en forma pública; cualquier usuario puede tener acceso al contenido.
    - **private** El contenido debe almacenarse en forma privada en el navegador del usuario; solo el usuario tiene acceso al contenido.
    - **no-store** El contenido no debe almacenarse.
    - **no-cache** El contenido puede almacenarse en la cache pero el navegador validará si el contenido ha sido modificado desde la fecha indicada por el servidor mediante el encabezado Last-Modified enviando al servidor el encabezado If-Modified-Since. Esta opción se utiliza por omisión.
    - **max-age=_tiempo_** indica el tiempo en segundo que se guardará el contenido en la cache.
    - **inmutable** indica que el contenido no será modificado nunca por el servidor.
    
      
    Es posible incluir varias opciones separadas por comas, considerando que las opciones más restrictivas pueden anular a las más permisivas.  
      
      
    **El encabezado Content-Disposition  
    **  
    El encabezado Content-Disposition es enviado por el servidor, para indicar al navegador que guarde en el disco local el contenido que regresa una petición GET, en lugar de mostrarlo en la pantalla.  
      
    Por ejemplo, el siguiente encabezado indica al navegador que guarde el archivo descargado con el nombre "documento.pdf":  
      
    
    Content-Disposition: attachment; filename="documento.pdf"
    
      
    
    **¿Cómo obtener la IP del cliente?**
    
    Para desplegar la dirección IP del cliente que se conectó al servidor HTTP, podemos incluir la siguiente instrucción al principio del método run():  
    
    System.out.println(conexion.getRemoteSocketAddress().toString());
    
    En general, los servidores guardan en una bitácora la fecha y hora, la IP del cliente y la petición GET de manera que se pueda monitorear cualquier ataque que reciba el servidor HTTP.
    
      
    
    #### Actividades individuales a realizar
    
      
    
    En esta actividad vamos a utilizar una máquina virtual en la nube, para probar la ejecución del servidor HTTP visto en clase:
    
    1. Crear una máquina virtual con Ubuntu 20, con 1GB de RAM y 30 GB de disco duro.
    2. Instalar el JDK 8 o superior en la máquina virtual.
    3. Abrir el puerto 80 en la máquina virtual.
    4. Compilar el programa [ServidorHTTP.java][[notas]](https://m4gm.com/moodle/mod/resource/view.php?id=2253 "ServidorHTTP.java") en la máquina virtual. El servidor deberá abrir el puerto 80.
    5. Ejecutar el programa [ServidorHTTP.java](https://m4gm.com/moodle/mod/resource/view.php?id=2253 "ServidorHTTP.java") en la maquina virtual utilizando "sudo". Es necesario utilizar "sudo" debido a que el servidor abre el puerto 80, sin embargo se podría ejecutar el servidor sin usar "sudo" si el servidor abre un puerto mayor a 1023, p.e. 8080, y se utiliza el comando iptables para mapear el puerto 80 al puerto 8080.
    6. Ingresar la URL **http://_ip-máquina-virtual_/hola** en un teléfono celular (_ip-máquina-virtual_ es la IP pública de la máquina virtual), notar que en la terminal de la máquina virtual se despliega la petición que envía el cliente y los encabezados.
    7. Para ahorrar el saldo de la cuenta de Azure for Students, es muy importante **eliminar la máquina virtual** cuando ya no se utilice.
    
    

- #### Clase del día - 11/09/2024
    
    La clase de hoy vamos a ver como implementar un cliente y un servidor mediante sockets seguros.  
    
    Primeramente vamos a explicar los conceptos básicos de PKI (_Public Key Infrastructure_).
    
      
    
    **Encriptado y desencriptado simétrico**  
    
    La criptografía simétrica es un conjunto de algoritmos que permiten encriptar y desencriptar utilizando la misma clave, conocida como _clave secreta_ o _clave privada_.
    
    Ejemplos de algoritmos simétricos son el AES-128, AES-256, RC4, RC5, DES, 3DES, entre otros.
    
    Los algoritmos simétricos son muy rápidos, sin embargo resulta complicado intercambiar las claves.
    
    Por ejemplo, supongamos que un amigo se va a estudiar a otro país y en un momento dado te pide le envíes un documento electrónico utilizando email. Desde luego habría que encriptar el documento para evitar que alguna otra persona pudiera hacer mal uso de él.
    
    El problema es que ambos deberían tener la clave para encriptar y desencriptar. A este problema se le conoce como problema de distribución de clave (_key distribution problem_).  
    
    La única solución es que ambos hayan compartido la clave para encriptar y desencriptar antes del viaje, ya que tampoco es seguro enviar la clave por email.

    **
    
    **Encriptado y desencriptado asimétrico**
    
    Una mejor solución al problema de distribución de claves es el uso de la criptografía asimétrica.  
    
    En la criptografía asimétrica el destinatario del mensaje tienen dos claves, una llamada _clave privada_ y otra llamada _clave pública_.
    
    La clave privada es una clave que mantiene en secreto el destinatario de los datos, mientras que la clave pública es una clave que puede conocer cualquiera.
    
    En la criptografía asimétrica (también llamada criptografía de llave pública o PKI: __Public Key Infrastructure__), el originario utiliza la clave pública del destinatario para encriptar los datos. Entonces el destinatario utiliza su clave privada para desencriptar los datos encriptados y obtener los datos en claro.
    


    
      
    
    **Firma digital**
    
    El par de claves pública y privada pueden utilizarse para autenticar un documento electrónico. A esta autenticación se le llama **firma digital**.  
    
    El efecto de una firma digital es el mismo que tiene una firma autógrafa, esto es, el **no repudio** de un documento (la capacidad de probar que el documento procede del firmante del mismo).
    
    Supongamos que vamos a enviar un documento (datos) a un destinatario. Para garantizar que el documento procede de un origen determinado, el originario genera un hash de los datos y encripta el hash con su clave privada (la cual solo es conocida por el originario). Al hash encriptado le llamamos la firma digital del documento.
    

    **
    
    Entonces el originario envía al destinatario el documento y la firma digital respectiva.
    
    Para verificar la firma, el destinatario desencripta la firma digital utilizando la clave pública del originario, entonces obtiene el hash del documento. Así mismo, el destinatario genera el hash del documento recibido.
    
    Si los dos hashes son iguales, entonces podemos estar seguros que el documento recibido procede del propietario de la clave pública y que el documento no ha sido modificado, debido a que cualquier modificación en el documento cambiaría el hash.
    
      
    
    **Certificado digital**
    
    Ahora bien, ¿Cómo sabemos que una clave pública pertenece a una persona u organismo determinado?
    
    Si el originario nos envió su clave pública por email, y sabemos con certeza que la dirección de correo electrónico pertenece a ésta persona, entonces concluimos que la clave pública pertenece a ésta persona de tal manera que podemos verificar la firma digital de cualquier documento que nos envíe.
    
    Sin embargo, no siempre podemos conocer a ciencia cierta que una dirección de correo electrónico pertenece a una persona determinada.
    
    Para resolver el problema de la identidad de una clave pública, se utiliza un documento electrónico llamado **certificado digital**.
    
    Un certificado digital es un documento electrónico que contiene, entre otros datos: la **identidad** de una persona u organización, las fechas de validez del certificado, la **clave pública** de la persona u organización y la **firma digital** de los datos anteriores.
    
    La clave pública que contiene el certificado está asociada a una clave privada que solo conoce la persona u organización propietaria del certificado digital. Para mayor seguridad, la clave privada generalmente se encripta con una clave simétrica.
    
    El certificado digital es firmado por una **autoridad certificadora** (CA), la cual es una organización registrada en el sistema operativo de nuestra computadora como una organización de confianza. El sistema operativo cuenta con un **repositorio de certificados de confianza**; en este repositorio se instalan los certificados de las autoridades certificadoras en las que confiamos.
    
    El estándar más utilizado para certificados digitales es el X.509
    
    Por default, el sistema operativo incluye en el repositorio de certificados de confianza los certificados de las autoridades certificadoras reconocidas internacionalmente. A estos certificados se le conoce como certificados raíz (_root_).
    
    Existen dos tipos de certificados, los certificados autofirmados y los certificados firmados por una CA.
    
    **Certificado autofirmado**
    
    Un certificado autofirmado es aquel que el usuario crea. Al crear un certificado autofirmado se crea un par de claves pública y privada, la clave pública se incluye en el certificado y este se firma utilizando la clave privada.
    
    Los datos de identidad en el certificado autofirmado los captura el usuario al crear el certificado.
    
    **Certificado firmado por una autoridad certificadora (CA)**
    
    Un certificado firmado por una autoridad certificadora (CA) es un certificado el cual ha sido firmado por un organismo que actúa como autoridad, dicha autoridad garantiza que el certificado pertenece a una determinada persona u organización.
    
    Un certificado de CA es similar a una credencial, la cual contiene el nombre, la fotografía y demás información de una persona; para garantizar que los datos de la credencial corresponden a la persona, la credencial deberá ser firmada por una autoridad.
    
    Los certificados de autoridad certificadora los debemos comprar a un proveedor de certificados digitales  (p.e. [cheapsslsecurity.com](https://cheapsslsecurity.com/)).
    
    Existen dos tipos de certificados firmados por una CA, aquellos que verifican dominio y aquellos que adicionalmente verifican la empresa.
    
    Para poder tener un certificado con **verificación de dominio**, es necesario ser propietario de un dominio.
    
    Por otra parte, para poder tener un certificado con **verificación de empresa**, es necesario tener una empresa y un dominio.
    
    Cuando se adquiere un certificado firmado por una CA, además del certificado, se obtiene un archivo conocido como _bundle_, el cual contiene los certificados de CA que forman una **ruta de certificación** desde el certificado emitido, hasta un certificado raíz preinstalado en la computadora. A los certificados en el _bundle_ se les llama **certificados intermedios**.
    
    Veamos un ejemplo de certificado digital con verificación de dominio, en este caso el dominio es m4gm.com
    
      
    

    **
    

    

    
      
    
      
    
    **Cliente - Servidor con sockets seguros**  
    
    Para que un cliente y un servidor se comuniquen mediante sockets seguros, se requiere un certificado digital.
    
    Para propósitos de prueba, vamos a crear un certificado autofirmado utilizando el programa keytool incluido en el JDK.
    
    En Java los certificados y las llaves privadas correspondientes se almacenan en un archivo llamado "keystore" o repositorio de certificados.
    
    Para crear el repositorio de certificados "keystore_servidor.jks" ejecutamos el siguiente comando:
    
    keytool -genkeypair -keyalg RSA -alias certificado_servidor -keystore keystore_servidor.jks -storepass 1234567
    
    La opción **genkeypair** genera un par de claves pública y privada.
    
    La clave pública se pone en un certificado autofirmado con un solo elemento en la ruta de certificación. El **alias**, en este caso "certificado_servidor", define un nombre con el cual vamos a identificar el certificado. **Keystore** es un archivo (repositorio) donde se va a almacenar el certificado y la clave privada correspondiente. **Keyalg** es el algoritmo a utilizar para generar el par de claves, en este caso RSA. **storepass** es la contraseña para el keystore.
    
    Entonces se deberá capturar los datos del certificado, por ejemplo se puede capturar los siguientes datos:
    
    ¿Cuáles son su nombre y su apellido?  
      [Unknown]:  **nombre**  
    ¿Cuál es el nombre de su unidad de organización?  
      [Unknown]:  **unidad**  
    ¿Cuál es el nombre de su organización?  
      [Unknown]:  **organizacion**  
    ¿Cuál es el nombre de su ciudad o localidad?  
      [Unknown]:  **CDMX**  
    ¿Cuál es el nombre de su estado o provincia?  
      [Unknown]:  **CDMX**  
    ¿Cuál es el código de país de dos letras de la unidad?  
      [Unknown]:  **MX**  
    ¿Es correcto CN=nombre, OU=unidad, O=organizacion, L=CDMX, ST=CDMX, C=MX?  
      [no]:  **si**
    
    Introduzca la contraseña de clave para <certificado_servidor>  
    
            (INTRO si es la misma contraseña que la del almacén de claves):
    
    IMPORTANTE: Para Java, la clave del certificado <certificado_servidor> y la clave (storepass) del almacén de claves (keystore) deben ser las mismas, en este caso: 1234567
    
    NOTA: En un certificado firmado por una CA, el campo CN (nombre común) contiene el nombre del dominio que ampara el certificado digital. Cuando un navegador web se conecta a un servidor web, el navegador recibe el certificado del servidor, compara el campo CN con el dominio indicado en la URL, si no son iguales, el navegador despliega un mensaje de advertencia indicando que el sitio no es de confianza.
    
    Debido a que el keystore "keystore_servidor.jks" contiene la llave privada del servidor, es conveniente crear un keystore para el cliente, el cual contenga solamente el certificado del servidor, para esto vamos a exportar el certificado "certificado_servidor" contenido en el keystore:
    
    keytool -exportcert -keystore keystore_servidor.jks -alias certificado_servidor -rfc -file certificado_servidor.pem
    
    La opción **exportcert** lee del keystore el certificado identificado por el alias y genera un archivo texto que contiene el certificado, en este caso se genera el archivo certificado_servidor.pem
    
    Entonces vamos a crear un keystore que utilizará el cliente (repositorio de confianza), este keystore deberá contener el certificado del servidor:
    
    keytool -import -alias certificado_servidor -file certificado_servidor.pem -keystore keystore_cliente.jks -storepass 123456
    
    La opción **import** lee el archivo certificado_servidor.pem e inserta el certificado en el keytore keystore_cliente.jks, identificando el certificado mediante el alias. **Storepass** es la contraseña del keystore.
    
    En la siguiente figura podemos ver que el servidor utilizará el keystore que contiene el certificado del servidor y la clave privada respectiva. El cliente utilizará el keystore que solo contiene el certificado del servidor.
    
      
    

    
      
    
    Por otra parte, también es posible que los programas cliente y servidor utilicen un certificado firmado por una CA, en este caso será necesario que el keystore que utilizará el servidor contenga: 1) los certificados intermedios, 2) el certificado del servidor y 3) la clave privada correspondiente.
    
    Debido a que el certificado del servidor es un certificado de confianza emitido por una CA, **no es necesario** crear el repositorio keystore_cliente.jks. Más adelante en el curso veremos el proceso de adquisición de un certificado digital para un dominio y cómo crear el keystore del servidor.
    
      
    

    
      
      
    
    Ahora veremos cómo crear un cliente y un servidor los cuales se comunicarán mediante sockets seguros.
    
    **[ClienteSSL.java](https://m4gm.com/moodle/mod/resource/view.php?id=2812 "ClienteSSL.java")**
    
    Primeramente asignamos a la propiedad "javax.net.ssl.trustStore" el nombre del keystore del cliente, y a la propiedad "javax.net.ssl.trustStorePassword" la contraseña del keystore del cliente:
    
    System.setProperty("javax.net.ssl.trustStore","keystore_cliente.jks");  
    System.setProperty("javax.net.ssl.trustStorePassword","123456");
    
    **Nota**. El método System.setProperty(String nombre_propiedad,String valor_propiedad) permite asignar un valor a una propiedad (variable) del sistema (Java). Debido a que las propiedades son "globales", es posible recuperar el valor de una propiedad del sistema desde cualquier parte del código, utilizando el método System.getProperty(String nombre_propiedad).
    
    Ahora el cliente debe crear una instancia de la clase SSLSocketFactory:
    
    SSLSocketFactory cliente = (SSLSocketFactory) SSLSocketFactory.getDefault();
    
    Entonces vamos a crear un socket que se conectará al servidor invocando el método createSocket de la clase SSLSocketFactory. En este caso el servidor se llama "localhost" (computadora local) y el puerto abierto en el servidor es el 50000.
    
    Socket conexion = cliente.createSocket("localhost",50000);
    
    Abrimos los streams de salida y de entrada como lo hicimos anteriormente.
    
    DataOutputStream salida = new DataOutputStream(conexion.getOutputStream());  
    DataInputStream entrada = new DataInputStream(conexion.getInputStream());
    
    Ahora podemos enviar datos al servidor, por ejemplo vamos a enviar un double:
    
    salida.writeDouble(123456789.123456789);
    
    Para terminar el programa cerramos la conexión con el servidor (al cerrar el socket se cierran también los streams asociados), en este caso vamos a poner un retardo de un segundo antes de cerrar la conexión, para permitir que el servidor tenga tiempo de recibir los datos:
    
    Thread.sleep(1000);
    conexion.close();
    
    **[ServidorSSL.java](https://m4gm.com/moodle/mod/resource/view.php?id=2813 "ServidorSSL.java")**  
    
    Al igual que el cliente, el servidor requiere el nombre del keystore y la contraseña, entonces asignamos a la propiedad "javax.net.ssl.keystore" el nombre del keystore del servidor, y a la propiedad "javax.net.ssl.keystorePassword" la contraseña del keystore del servidor:
    
    System.setProperty("javax.net.ssl.keyStore","keystore_servidor.jks");  
    System.setProperty("javax.net.ssl.keyStorePassword","1234567");
    
    El servidor debe crear una instancia de la clase SSLServerSocketFactory:  
    
    SSLServerSocketFactory socket_factory = (SSLServerSocketFactory) SSLServerSocketFactory.getDefault();
    
    Vamos a crear un socket servidor que va a abrir, en este caso, el puerto 50000 utilizando el método createServerSocket de la clase SSLServerSocketFactory:  
    
    ServerSocket socket_servidor = socket_factory.createServerSocket(50000);
    
    Ahora invocamos el método **accept** de la clase ServerSocket. Cuando se recibe la conexión el método **accept** regresa un socket:
    
    Socket conexion = socket_servidor.accept();
    
    Abrimos los streams de salida y de entrada:
    
    DataOutputStream salida = new DataOutputStream(conexion.getOutputStream());  
    DataInputStream entrada = new DataInputStream(conexion.getInputStream());
    
    Ahora podemos recibir datos del cliente, en este caso vamos a recibir un double:
    
    double x = entrada.readDouble();  
    System.out.println(x);
    
    Finalmente, cerramos la conexión:
    
    conexion.close();
    
      
    
    **Nota**. Si el certificado del servidor es un certificado emitido por una CA entonces no es necesario crear el repositorio keystore_cliente.jks, por tanto el programa [ClienteSSL.java](https://m4gm.com/moodle/mod/resource/view.php?id=2812 "ClienteSSL.java") no requiere inicializar las propiedades javax.net.ssl.trustStore y javax.net.ssl.trustStorePassword.
    
      
    **Implementación de un servidor HTTPS  
    **  
    
    Un servidor HTTPS es un servidor HTTP con sockets seguros, por lo tanto es muy sencillo convertir nuestro servidor HTTP en un servidor HTTPS.  
      
    Como vimos anteriormente, para establecer una comunicación segura entre un cliente y un servidor es necesario contar con un certificado digital, el cual puede ser un certificado autofirmado o bien, un certificado firmado por una autoridad certificadora (CA).  
      
    En el ejemplo que sigue utilizaremos el mismo repositorio que creamos anteriormente (keystore_servidor.jks), el cual contiene la llave privada y el certificado digital del servidor.  
      
    Debido a que el certificado autofirmado no es reconocido por el navegador como un certificado válido, al acceder a nuestro servidor HTTPS el navegador desplegará un mensaje de advertencia, indicando que el certificado no es de confianza porque está autofirmado.  
      
    Para propósito de pruebas, se puede dar clic al botón "Avanzado" y continuar, toda vez que el certificado lo hemos firmado nosotros. Cabe aclarar que en general **no se debe acceder** a una página web si el navegador despliega un mensaje de advertencia.  
      
    **[ServidorHTTPS.java](https://m4gm.com/moodle/mod/resource/view.php?id=2814 "ServidorHTTPS.java")**  
      
    El único cambio que haremos en el código del servidor HTTP, es agregar las instrucciones necesarias para crear el socket servidor seguro:  
    
        public static void main(String[] args) throws Exception  
        {  
            int puerto = 8443;  
    	**System.setProperty("javax.net.ssl.keyStore","keystore_servidor.jks");  
            System.setProperty("javax.net.ssl.keyStorePassword","1234567");  
    	SSLServerSocketFactory socket_factory = (SSLServerSocketFactory)SSLServerSocketFactory.getDefault();  
            ServerSocket servidor = socket_factory.createServerSocket(puerto);**  
            System.out.println("Servidor HTTPS ejecutando en el puerto: " + puerto);
    
            for(;;)  
            {  
              Socket conexion = servidor.accept();  
              new Worker(conexion).start();  
            }  
        }  
    
    En este caso el servidor utilizará el puerto 8443 aunque podría utilizar otro puerto, por ejemplo, el puerto 443 el cual es el estándar para HTTPS.
    
    Es recomendable que el servidor utilice un puerto mayor a 1024 ya que los puertos menores o iguales a 1024 solo pueden ser abiertos por procesos que ejecutan con permisos de administración (sudo).
    
    Cuando un servidor (HTTP, HTTPS, DBMS, etc.) ejecuta con permisos de administración se corre el riesgo de que un atacante tome el control del servidor y con ello pueda acceder a recursos del sistema.
    
    Para probar el acceso a nuestro servidor HTTPS solo tenemos que ingresar la siguiente URL en un navegador:
    
    https://localhost:8443/hola
    
    Más adelante veremos cómo adquirir un certificado firmado por una autoridad certificadora y cómo crear un repositorio (keystore) con este certificado, de manera que cualquier navegador pueda conectarse a nuestro servidor HTTPS sin ningún problema de seguridad.  
      
      
    **Referencia**  
      
    [Navegar Seguro por Internet  
    ](https://upcommons.upc.edu/bitstream/handle/2099/9857/Article010.pdf)  
    
    #### Actividades individuales a realizar
    
      
    
    Probar los programas [ClienteSSL.java](https://m4gm.com/moodle/mod/resource/view.php?id=2812 "ClienteSSL.java") y [ServidorSSL.java](https://m4gm.com/moodle/mod/resource/view.php?id=2813 "ServidorSSL.java")
    
    1. Crear los repositorios de certificados (keystores) para el cliente y para el servidor.
    2. Compilar y ejecutar los programas [ClienteSSL.java](https://m4gm.com/moodle/mod/resource/view.php?id=2812 "ClienteSSL.java") y [ServidorSSL.java](https://m4gm.com/moodle/mod/resource/view.php?id=2813 "ServidorSSL.java")
    
      
    Probar el programa [ServidorHTTPS.java](https://m4gm.com/moodle/mod/resource/view.php?id=2814 "ServidorHTTPS.java")  
      
    
    1. Crear una máquina virtual con Ubuntu en Azure y 1GB de RAM. Abrir el puerto 443.
    
    2. Crear un keystore con un certificado autofirmado, tal como vimos en clase.
    
    3. Compilar y ejecutar el servidor HTTPS en la máquina virtual. El servidor HTTPS deberá utilizar el keystore creado anteriormente.
    
    4. Ingresar la URL **https://_ip-máquina-virtual_/hola** en un teléfono celular, _ip-máquina-virtual_ es la IP pública de la máquina virtual 
    
    ¿Por qué el navegador muestra una advertencia?  
    ¿Es posible conectarse al servidor a pesar de la advertencia?  
    
    5. Instalar el certificado autofirmado como un certificado de confianza en Windows (consultar ChatGPT para ver cómo instalar un certificado de confianza en Windows).
    
    6. Ingresar nuevamente la URL **https://_ip-máquina-virtual_/hola** en el teléfono celular
    
    ¿El navegador sigue mostrando la advertencia?
    
      
      
    
    ![No finalizado; Clase del día - 11/09/2024La clase de hoy vamos a .... Seleccione para marcar como finalizado](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/i/completion-manual-n "No finalizado; Clase del día - 11/09/2024La clase de hoy vamos a .... Seleccione para marcar como finalizado")
    
- [![](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/f/sourcecode)ClienteSSL.javaArchivo](https://m4gm.com/moodle/mod/resource/view.php?id=2812)
    
    ![No finalizado; ClienteSSL.java. Seleccione para marcar como finalizado](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/i/completion-manual-n "No finalizado; ClienteSSL.java. Seleccione para marcar como finalizado")
    
- [![](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/f/sourcecode)ServidorSSL.javaArchivo](https://m4gm.com/moodle/mod/resource/view.php?id=2813)
    
    ![No finalizado; ServidorSSL.java. Seleccione para marcar como finalizado](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/i/completion-manual-n "No finalizado; ServidorSSL.java. Seleccione para marcar como finalizado")
    
- [![](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/f/sourcecode)ServidorHTTPS.javaArchivo](https://m4gm.com/moodle/mod/resource/view.php?id=2814)
    
    ![No finalizado; ServidorHTTPS.java. Seleccione para marcar como finalizado](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/i/completion-manual-n "No finalizado; ServidorHTTPS.java. Seleccione para marcar como finalizado")
    
- ####   
    Clase del día - 13/09/2024
    
    **El tiempo en los sistemas distribuidos**
    
      
    
    El tiempo es una referencia que utilizan los sistemas distribuidos en varias situaciones.  
    
    Supongamos una plataforma de comercio electrónico que funciona a nivel global. En cada país se tiene un servidor con una base de datos donde se registran las compras, incluyendo la fecha y hora en la que se realiza cada compra.
    
    Para consolidar las compras a nivel mundial cada servidor debe enviar los datos a un servidor central.
    
    Sin embargo, no es posible ordenar las compras por fecha debido a dos situaciones:
    
    1. Cada compra se ha registrado con la fecha y hora local.
    2. No es posible garantizar que los relojes de los servidores funcionen a la misma velocidad.  
        
    
      
    
    Para ilustrar este problema supongamos que un cliente en México realiza una compra a las 8 PM, y un cliente en España realiza una compra a las 2 AM del día siguiente. ¿Quién compró primero?  
    
      
    
    Aparentemente el cliente en México realizó la compra antes que el cliente en España, debido a que la fecha de la compra del cliente en México es un día anterior a la fecha de la compra del cliente en España.
    
      
    
    Sin embargo, en realidad el cliente en España realizó la compra una hora antes que el cliente en México, debido a que la diferencia horaria entre México y España es de 7 horas.
    
      
    

    
    Mapa de los husos horarios oficiales vigentes (dominio público)  
    
      
    
    La solución a este problema es registrar en las bases de datos la **fecha y hora global** (en un campo de tipo Datetime o Timestamp) en lugar de la fecha y hora local. Además, los servidores deberán sincronizar sus relojes internos a una misma hora.  
    
      
    
    Por otra parte, si los servidores no requieren consolidar las compras, tampoco será necesario que exista un acuerdo en los tiempos que marcan sus relojes.  
    
      
    
    El ejemplo anterior ilustra una regla muy importante de los sistemas distribuidos, la cual podemos enunciar de la siguiente manera: _si dos computadoras no están conectadas, entonces no requieren sincronizar sus tiempos_.
    
      
    
    **Sincronización de relojes**
    
      
    
    Sincronizar dos o más relojes significa que los servidores se ponen de acuerdo en una misma hora.
    
      
    
    Notar que un grupo de servidores pueden ponerse de acuerdo en una hora y otro grupo de servidores puede ponerse de acuerdo en otra hora; solo si ambos grupos de servidores se conectan, entonces ambos grupos de servidores deberán acordar una hora.
    
      
    
    Como se dijo anteriormente, **el tiempo es una referencia para establecer un orden** en una secuencia de eventos (como serían las compras en una plataforma de comercio electrónico).
    
      
    
    **Segundos solares  
    **
    
      
    
    El concepto de tiempo que utilizamos en la práctica se basa en la percepción que tenemos del día.
    
      
    
    Un día es un período de luz y obscuridad debido a la rotación de la tierra sobre su eje.  
    
      
    
    Dividimos convencionalmente el día en 24 horas, cada hora en 60 minutos y cada minuto en 60 segundos.
    
      
    
    Por tanto, la tierra tarda 86,400 segundos en dar una vuelta sobre su eje, en términos de velocidad angular estamos hablando de 360/86400=0.00416 grados/segundo.
    
      
    
    A la fracción 1/86400 de día le llamamos **segundo solar**.  
    
      
    
    Sin embargo la velocidad angular de la tierra no es constante, debido a que la rotación de la tierra se está deteniendo lentamente.  
    
      
    
    **Segundos atómicos  
    **
    
      
    
    Una forma más precisa de medir el tiempo es utilizar un reloj atómico de Cesio 133.
    
      
    
    En un reloj atómico se aplica microondas con diferentes frecuencias a átomos de Cesio 133, entonces los electrones del átomo de Cesio 133 absorben energía y cambian de estado; posteriormente los átomos regresan a su estado basal emitiendo fotones.
    
      
    
    A la frecuencia que produce más cambios de estado en los electrones del átomo de Cesio 133 se le llama _frecuencia natural de resonancia_.
    
      
    
    La frecuencia natural de resonancia del Cesio 133 es de 9,192,631,770 ciclos/segundo, es decir, el átomo de Cesio 133 muestra un máximo de absorción de energía cuando se le aplica microondas con una frecuencia de 9,192,631,770 Hertzios.
    
      
    
    Entonces se define el **segundo atómico** como el recíproco de la frecuencia natural de resonancia del Cesio 133 (recordar que el periodo de una onda es el recíproco de su frecuencia).
    
      
    
    Los relojes atómicos de Cesio 133 son extremadamente precisos, ya que independientemente de las condiciones ambientales (temperatura, presión, etc.), se adelantan o atrasan un segundo cada 300 millones de años.
    
      
    
    Los relojes atómicos son tan precisos que se han utilizado para probar los postulados de la teoría general de la relatividad, la cual predice la dilatación del tiempo debidos a la distorsión que causa la gravedad al espacio-tiempo.
    
      
    
    Utilizando relojes atómicos de Cesio 133 se ha demostrado que el tiempo no transcurre a la misma velocidad a diferentes altitudes, ya que al nivel del mar, donde la gravedad es mayor, el tiempo se dilata (transcurre más lentamente) con respecto al tiempo medido en una montaña elevada donde la gravedad es menor.
    
      
    
    Por ejemplo, un reloj atómico en un satélite GPS (a unos 20,000 Km de altura), se adelanta 7 microsegundos al día con respecto a un reloj atómico en la superficie de la tierra.  
    
      
    
    A este fenómeno se le conoce como _dilatación gravitacional del tiempo_.
    
      
    
      
    
    **Tiempo atómico internacional TAI  
    **
    
      
    
    Se define el tiempo atómico internacional (TAI) como el promedio de los segundos atómicos transcurridos desde el 1 de enero de 1958, dicho promedio obtenido de casi 70 relojes de Cesio 133 al rededor del mundo.  
    
      
    
    **Tiempo universal coordinado UTC  
    **
    
      
    
    El tiempo universal coordinado UTC (_Coordinated Universal Time_) es el estándar de tiempo que regula actualmente el tiempo de los relojes a nivel internacional.  
    
      
    
    El tiempo UTC ha reemplazado el tiempo medio de Greenwich GMT.
    
      
    
    El tiempo GMT toma como referencia la posición del sol a medio día. Tanto el tiempo GMT como el tiempo UTC consideran el día solar compuesto por 86,400 segundos solares.  
    
      
    
    Debido a que nuestro planeta disminuye su velocidad angular lentamente, el segundo solar dura más que el segundo atómico.
    
      
    
    Para sincronizar los segundos UTC con los segundos TAI, el tiempo UTC se debe “adelantar” para alcanzar el tiempo TAI, para esto “se salta” un segundo UTC una vez al año; se dice entonces que se introducen **segundos vacíos** en el tiempo UTC.  
    
      
    
    Por ejemplo, en el siguiente diagrama se muestra cómo los segundos solares son más largos que los segundos atómicos, en esta caso para sincronizar los segundos solares (UTC) con los segundos atómicos (TAI), se salta del segundo 6 al 8, es decir, el segundo "vacío" es el segundo 7:
    
      
    
    
      
    
    Los proveedores de nube han adoptado el uso del tiempo UTC para los relojes en las máquinas virtuales, por ejemplo cuando se ejecuta el comando **date** en una máquinas virtual con Ubuntu en Azure, se obtiene la fecha y hora UTC.
    
      
    
      
    
    **Network Time Protocol - NTP**  
    
      
    
    El protocolo de tiempo de red (Network Time Protocol - NTP) define un procedimiento centralizado para la sincronización de relojes.
    
      
    
    En este procedimiento los clientes consultan un servidor de tiempo, el cual podría contar con un reloj atómico o estar sincronizado con el tiempo atómico internacional (TAI).
    
      
    
    Los relojes atómicos son recursos muy costosos, además el servidor de tiempo puede saturarse al recibir muchas peticiones, por esta razón se suele implementar el mismo procedimiento sobre una topología de árbol.
    
      
    
    Los servidores de los estratos superiores del árbol son más exactos que los servidores de estratos inferiores, de tal manera que el servidor en la raíz, llamado servidor de estrato 1, contará con un reloj atómico llamado reloj de referencia.
    
      
    

    
      
    
    En el protocolo NTP el servidor A se conecta al servidor de tiempo B, entonces el servidor B responde con los tiempos T2 y T3.
    
      
    
    T2 es el tiempo en que el servidor B recibe la conexión del servidor A y T3 es el tiempo en que el servidor B envía la respuesta al servidor A.
    
      
    
    T1 es el tiempo en que el servidor A se conecta al servidor B y T4 es el tiempo en que el servidor A recibe la respuesta del servidor B.
    
      
    
    Cuando el servidor A recibe la respuesta del servidor B, calcula el tiempo de respuesta Tres suponiendo que el tiempo que tarda el requerimiento Treq es igual al tiempo de respuesta Tres.
    
      
    
    T4-T1 = Treq + Tres + (T3-T2) = 2 Tres + (T3-T2)
    
      
    
    Despejando Tres el servidor A puede establecer su tiempo en T3+Tres, es decir, el tiempo que envió el servidor B más el tiempo que tarda en llegar la respuesta.
    
      
    
    **Instalación de NTP en Ubuntu**
    
      
    
    Para asegurar que un servidor Ubuntu mantiene su reloj sincronizado con el tiempo UTC, podemos instalar NTP en el servidor ejecutando los siguientes comandos:
    
      
    
    sudo apt-get update  
    sudo apt-get install ntp
    
      
    **Conclusiones  
    **  
    1. En una empresa, es muy importante que se configure el tiempo UTC en todas las computadoras de back-end, incluso aquellas que ejecutan sistemas locales.  
      
    Las máquinas virtuales que ejecutan en la nube utilizan el tiempo UTC, por esta razón, es recomendable que los servidores de la empresa también utilicen el tiempo UTC, de manera que no sea necesario modificar las aplicaciones cuando la empresa migre a la nube.  
      
    2. No se debe utilizar el tipo de dato Date (fecha) en la base de datos, es recomendable utilizar el tipo de dato Datetime (fecha-hora).  
      
    3. Un sistema no debe registrar la fecha-hora local en la base de datos; el sistema deberá registrar la fecha-hora UTC, de manera que el sistema esté preparado para migrar a la nube.  
      
    4. El front-end del sistema debe mostrar al usuario la fecha-hora local, mientras que el back-end debe guardar la fecha-hora UTC. El front-end deberá realizar la conversión hora-local a hora UTC y viceversa, es decir, el front-end enviará la fecha-hora UTC al back-end, así mismo, el back-end enviará al front-end la fecha-hora UTC.  
      
      
    
    #### Actividades individuales a realizar
    
      
    
    Vamos a ver cómo crear la imagen de una máquina virtual con Ubuntu en Azure y cómo crear máquinas virtuales a partir de la imagen.
    
    Una **máquina virtual generalizada** es un máquina virtual cuyo sistema operativo se ha despojado de la configuración específica y la configuración de usuarios.
    
    Una imagen generalizada es la captura de un sistema operativo de una máquina virtual generalizada..
    
    **Notas importantes**
    
    1. La captura de la imagen de una máquina virtual **inutiliza la máquina virtual** ya que una máquina virtual generalizada no se puede iniciar o modificar.  
    
    2. La generalización de una máquina virtual no implica que se borre toda la información confidencial que pudiera existir en la máquina virtual. Es muy importante considerar lo anterior si se va a redistribuir la imagen de la máquina virtual.
    
    3. La generalización de una máquina virtual no elimina el archivo /etc/resolv.conf (ver: [resolvconf](http://manpages.ubuntu.com/manpages/trusty/man8/resolvconf.8.html))
    
    4. La generalización de una máquina virtual deshabilita la contraseña de root.
    
    5. La opción +user del comando waagent elimina la última cuenta creada en la máquina virtual incluyendo el directorio del usuario. Si se desea conservar el usuario y el directorio, no se deberá utilizar la opción +user al generalizar la máquina virtual mediante el comando waagent.  
    
    6. Para generalizar una máquina virtual con Windows se utiliza el programa sysprep.exe, ver: [https://docs.microsoft.com/en-us/azure/virtual-machines/generalize](https://docs.microsoft.com/en-us/azure/virtual-machines/generalize).
    
    7. Una imagen se cobra de acuerdo al espacio en disco que ocupa, ver: [Precios de Managed Disks](https://azure.microsoft.com/es-es/pricing/details/managed-disks/).
    
    8. El tamaño del disco predeterminado en la imagen es el tamaño del disco de sistema operativo de la máquina virtual. Al crear la máquina virtual a partir de la imagen, el tamaño del disco de sistema operativo podrá ser mayor al que tenia la máquina virtual original, pero no podrá ser de menor tamaño.
    
    **Crear la imagen de una máquina virtual con Ubuntu  
    **
    
    Para generalizar la máquina virtual utilizaremos el agente **waagent** el cual elimina los datos específicos de la máquina virtual.
    
    1. Crear una máquina virtual con Ubuntu.
    
    2. Abrir una ventana cmd de Windows o una terminal de Linux o MacOs.
    
    3. Ejecutar el programa ssh en la ventana, pasando como parámetros el usuario (por ejemplo ubuntu) y la ip pública de la máquina virtual:
    
    ssh usuario@ip
    
    4. Para generalizar la máquina virtual y eliminar la última cuenta de usuario creada incluyendo el directorio del usuario, ejecutar el comando:  
    
    sudo waagent -deprovision+user
    
      
    
    Si se quiere conservar en la imagen la última cuenta de usuario creada, ejecutar el comando:
    
      
    
    sudo waagent -deprovision
    
      
    
    5. En el portal de Azure seleccionar la máquina virtual que se quiera capturar como imagen.
    
      
    
    6. Seleccionar la opción "Captura".
    
    6.1 En la opción "Compartir imagen con Shared Image Gallery" seleccionar "No, capturar solo una imagen administrada".  
    
    7. Marcar la casilla "Eliminar automáticamente esta máquina virtual después de crear la imagen", ya que una máquina virtual generalizada no se puede iniciar o modificar.  
    
    8. Ingresar el nombre de la imagen a crear.
    
    9. Dar clic en el botón "Crear".
    
    10. Dar clic en la campana de notificaciones para verificar que se haya creado la imagen de la máquina virtual.
    
      
    
    **Crear una máquina virtual a partir de una imagen**
    
    1. En la sección "Todos los recursos" en el portal de Azure seleccionar la imagen de la máquina virtual.
    
      
    
    2. Seleccionar la opción "+Crear máquina virtual".
    
    3. Seleccionar el grupo de recursos donde se creará la máquina virtual.
    
    4. Ingresar el nombre de la máquina virtual.
    
    5. Seleccionar el tamaño de la máquina virtual.
    
    6. Seleccionar el tipo de autenticación (Clave pública SSH o Contraseña). En su caso, ingresar el usuario y contraseña.
    
    7. Dar clic en el botón "Siguiente: Discos >"
    
    8. Seleccionar el tipo de disco del sistema operativo (p.e. HDD estándar). Notar que el tamaño predeterminado del disco es el tamaño del disco de sistema operativo de la máquina virtual original. Se puede seleccionar un tamaño mayor pero no un tamaño menor al tamaño del disco original.
    
    9. Si no hay otra configuración que se quiera realizar, dar clic en el botón "Revisar y crear".
    
    10. Dar clic en el botón "Crear".
    
      
    
    **Referencias**  
    
    [Captura de una imagen administrada de una máquina virtual generalizada en Azure](https://docs.microsoft.com/es-es/azure/virtual-machines/windows/capture-image-resource)  
    
    [Información y uso del agente de Linux de Azure](https://docs.microsoft.com/es-mx/azure/virtual-machines/extensions/agent-linux)
    
    Reproducir Vídeo
    
      
    
    Ahora vamos a ver cómo crear la imagen de una máquina virtual con Windows y cómo crear máquinas virtuales a partir de la imagen.
    
    **Notas importantes**  
    
    1. La captura de la imagen de una máquina virtual **inutiliza la máquina virtual** ya que una máquina virtual generalizada no se puede iniciar o modificar.  
    
    2. La generalización de una máquina virtual no implica que se borre toda la información confidencial que pudiera existir en la máquina virtual. Es muy importante considerar lo anterior si se va a re-distribuir la imagen de la máquina virtual.
    
    3. La generalización de una máquina virtual elimina las variables de ambiente de sistema y de usuario.
    
    4. Una imagen se cobra de acuerdo al espacio en disco que ocupa, ver: [Precios de Managed Disks](https://azure.microsoft.com/es-es/pricing/details/managed-disks/).
    
    **Crear la imagen de una máquina virtual con Windows  
    **
    
    Para generalizar la máquina virtual utilizaremos el programa sysprep.exe el cual elimina los datos específicos de la máquina virtual.
    
    1. Crear una máquina virtual con Windows Server 2012.
    
    2. Conectarse a la máquina virtual utilizando escritorio remoto.
    
    3. Para generalizar la máquina virtual y así eliminar la información de seguridad y las cuentas de usuarios, dar clic derecho en el botón de inicio de Windows. Entonces seleccionar "Command Promt (Admin)" y ejecutar en la ventana el siguiente programa:
    
    \Windows\System32\Sysprep\sysprep.exe
    
    4. Seleccionar "Enter System Out-of-Box Experience (OOBE)"**,** checar la opción "Generalize", seleccionar "Shutdown**"** en Shutdown Options y presionar el botón **OK**.
    
      
    
    5. En el portal de Azure seleccionar la máquina virtual que se quiera capturar como imagen.  
    
      
    
    6. Seleccionar la opción "Captura".
    
    6.1 En la opción "Compartir imagen con Shared Image Gallery" seleccionar "No, capturar solo una imagen administrada".  
    
    7. Marcar la casilla "Eliminar automáticamente esta máquina virtual después de crear la imagen", ya que una máquina virtual generalizada no se puede iniciar o modificar.  
    
    8. Ingresar el nombre de la imagen a crear.
    
    9. Dar clic en el botón "Revisar y crear".  
    
    10. Dar clic en el botón "Crear".
    
    10. Dar clic en la campana de notificaciones para verificar que se haya creado la imagen de la máquina virtual.
    
    11. Eliminar la máquina virtual generalizada.
    
      
    
    **Crear una máquina virtual a partir de una imagen**
    
    1. En la sección "Todos los recursos" en el portal de Azure seleccionar la imagen de la máquina virtual.
    
      
    
    2. Seleccionar la opción "+Crear máquina virtual".
    
    3. Seleccionar el grupo de recursos donde se creará la máquina virtual.
    
    4. Ingresar el nombre de la máquina virtual.
    
    5. Seleccionar el tamaño de la máquina virtual.
    
    6. Seleccionar el tipo de autenticación (Clave pública SSH o Contraseña). En su caso, ingresar el usuario y contraseña.
    
    7. Dar clic en el botón "Siguiente: Discos >"
    
    8. Seleccionar el tipo de disco del sistema operativo (p.e. HDD estándar).
    
    9. Si no hay otra configuración que se quiera realizar, dar clic en el botón "Revisar y crear".
    
    10. Dar clic en el botón "Crear".
    
      
    
    Reproducir Vídeo
    
      
      
    
    ![No finalizado; Clase del día - 13/09/2024El tiempo en los sistema.... Seleccione para marcar como finalizado](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/i/completion-manual-n "No finalizado; Clase del día - 13/09/2024El tiempo en los sistema.... Seleccione para marcar como finalizado")
    
- #### Clase del día - 18/09/2024
    
      
    
    **Aprovisionamiento de recursos informáticos On-premise**
    
    En el pasado el aprovisionamiento de recursos informáticos _On-premise_ (en las instalaciones de la empresa) representaba el concurso de diferentes proveedores de bienes y servicios, como eran los representantes de ventas, ingenieros de preventa, fabricantes de los equipos, fabricante del sistema operativo, fabricante de la base de datos, agentes aduanales, transportistas, instaladores del _site_, proveedor de energía, proveedor de comunicaciones, instaladores del hardware, instaladores del software, entre otros.  
    
    Entonces, el aprovisionamiento de recursos informáticos era un proceso complejo y tardado, el cual culminaba con el sistema en producción.  
    
    Después había que reaprovisionar cuando crecían las necesidades de la empresa.
    
      
    **Cómputo como servicio  
    **  
    
    El concepto de cómputo en la nube (_cloud computing_) está basado en las ideas del profesor John McCarthy de la Universidad de Stanford.
    
    En un discurso en 1961, predijo que la tecnología de tiempo compartido (la posibilidad de que múltiples usuarios y procesos utilicen una misma computadora) podría llevar en el futuro, a ofrecer las capacidades de cómputo y las aplicaciones como **servicios públicos**.
    
    Esta idea se concretaría en lo que actualmente conocemos como cómputo en la nube, al ofrecer servicios virtualizados a nivel masivo en Internet.
    
    Por otra parte, en 1984 John Burdette Gage acuñó el slogan _The network is the computer_ para Sun Microsystems, el cual significa que la computadora de escritorio es una "ventana" a la red, y mediante el software apropiado, es posible transferir tareas de cómputo a otras computadoras.
    
    A la posibilidad de trasferir tareas de cómputo a otras computadoras se le conoce como _computation offloading_.
    
      
    
    **Fábricas de información**
    
    En 2006 aparece el artículo "The Information Factories" en la prestigiosa revista WIRED [1].
    
    En este artículo se presenta la idea de "fábricas de información" (_Information Factories_).
    
    El autor, George Gilder, argumenta que la tecnología de la información evoluciona hacia un modelo de **procesamiento** y **almacenamiento** de datos centralizados en grandes centros de datos.
    
    Estos centros de datos estarían equipados con grandes servidores y redes de alta velocidad.
    
    Entonces, en lugar de depender de computadoras personales, los usuarios accederán a **servicios informáticos** a través de redes de comunicación utilizando dispositivos más simples, como serían las computadoras portátiles y los dispositivos móviles como tabletas y teléfonos celulares.
    
    "_The desktop is dead. Welcome to the Internet cloud, where massive facilities across the globe will store all the data you'll ever use_", The Information Factories, George Gilder.  
    
    Este modelo de informática centralizada permitiría contar con capacidades "ilimitadas" de procesamiento y almacenamiento, lo cual proporcionará niveles de escalabilidad sin precedentes.
    
    Si bien George Gilder no introduce el concepto de **cómputo en la nube** como tal, su artículo explora las implicaciones sociales y económicas de este modelo de computación basado en la idea de "fábrica de información".
    
      
    
    #### Proveedores de servicios en la nube
    
    **Amazon**
    
    En 2006 Amazon lanzó la plataforma Amazon Web Services (AWS) incluyendo los servicios Elastic Computer (EC2) y Storage Cloud (S3).
    
    AWS popularizó el modelo de Infraestructura como Servicio (IaaS, _Infrastructure as a Service_), el cual permite a las empresas alquilar recursos de cómputo y almacenamiento en lugar de invertir en hardware propio.
    
    **Google**  
    
    En 2008 Google lanzó Google App Engine, inicialmente como una plataforma para desarrollar y alojar aplicaciones web.
    
    Posteriormente, Google lanza el servicio Google Cloud Storage en 2010 y en 2013 el servicio Google Compute Engine (GCE). Con estos servicios Google entra en el mercado de infraestructura como Servicio (IaaS).
    
    La marca Google Cloud Platform (GCP) se lanzó oficialmente en 2011.
    
    **Microsoft**  
    
    En 2010 Microsoft lanzó la plataforma Windows Azure (ahora conocida como Microsoft Azure), con servicios para desarrolladores al nivel de plataforma (PaaS), entre otros:
    
    - Windows Azure Compute para la ejecución de aplicaciones en la nube utilizando máquinas virtuales administradas por Microsoft.
    - Windows Azure Storage para el almacenamiento de datos estructurados y no estructurados.
    - Windows Azure SQL Database el cual es SQL Server en la nube.
    
    En 2012 Microsoft lanzó los servicios: 1) Azure Virtual Machines, con el cual Microsoft entra en el mercado de IaaS, 2) Azure Virtual Network el cual permite crear redes virtuales en la nube, 3) Azure Storage IaaS el cual ofrece almacenamiento para las máquinas virtuales.  
    
    En 2015 Microsoft lanza el servicio Azure Container Service el cual permite ejecutar contenedores Docker en Azure.
    
      
    
    **Definición de cómputo en la nube**
    
    El Instituto Nacional de Estándares y Tecnología (NIST) de Estados Unidos, define el cómputo en la nube de la siguiente manera [2]:
    
    "_**Cloud computing**_ _is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction_."
    
      
    
    #### Las cinco características esenciales del cómputo en la nube
    
    **1. Autoservicio bajo demanda**
    
    Los usuarios pueden unilateralmente aprovisionar automáticamente capacidades en la infraestructura del proveedor del servicio de nube, tales como tiempo de servidor, almacenamiento y red, de acuerdo a sus necesidades sin intervención humana.
    
    **2. Acceso amplio por medio de la red**
    
    Las capacidades que ofrece el proveedor de nube están disponibles a través de la red, y son accedidas mediante mecanismos estándares utilizando clientes heterogéneos como teléfonos celulares, tabletas, computadoras de escritorio, etc.
    
    **3. Recursos compartidos**
    
    Los recursos de cómputo del proveedor de nube son compartidos por múltiples usuarios usando un modelo “multiinquilino” (multitenant). Los recursos físicos y virtuales (procesamiento, almacenamiento, memoria, ancho de banda, etc.) son asignados y reasignados dinámicamente de acuerdo a las necesidades de los usuarios.
    
    Los recursos asignados son transparentes en términos de la ubicación, se manera que el usuario no tiene que saber qué recurso físico está utilizando. No obstante, el usuario puede determinar en qué región o datacenter creará los recursos virtuales.
    
    **4. Elasticidad**
    
    Las capacidades pueden ser aprovisionadas y des-aprovisionadas elásticamente (manualmente o automáticamente), permitiendo al usuario escalar hacia arriba o hacia abajo, horizontalmente o verticalmente, bajo demanda. La escalabilidad hacia arriba con frecuencia parece ser ilimitada.
    
    **5. Medición del servicios**
    
    Los recursos de nube pueden ser monitoreados con la finalidad de controlar y optimizar automáticamente su utilización. Este monitoreo se realiza a diferentes niveles de abstracción de acuerdo al tipo de servicio (almacenamiento, procesamiento, ancho de banda, cuentas de usuario, etc.).
    
      
    
    #### Los tres modelos de servicio del cómputo en la nube
    
    **1. Infraestructura como servicio**  
    
    En el nivel de Infraestructura como servicio o _Infrastructure as a Service_ (IaaS), el usuario puede aprovisionar procesamiento (máquinas virtuales), almacenamiento (discos virtuales), redes y otros servicios que le permiten ejecutar cualquier software. 
    
    En este nivel el usuario tiene el control de sistema operativo, el almacenamiento, algunos componentes de la red, y las aplicaciones que ejecutan sobre el sistema operativo.
    
    **2. Plataforma como servicio**
    
    En el nivel de plataforma como servicio o _Platform as a Service_ (PaaS), el usuario puede aprovisionar servicios de instancias de bases de datos, respaldos, ejecución de servicio web, plataformas de desarrollo y pruebas, y otros servicios sin la necesidad de aprovisionar o controlar la infraestructura subyacente (servicios de IaaS como serían la máquina virtual, la red o el almacenamiento).
    
    **3. Software como servicio**
    
    En el nivel de software como servicio o _Software as a Service_ (SaaS), el usuario puede utilizar las aplicaciones publicadas por el proveedor de nube, las cuales ejecutan sobre la infraestructura de nube. El usuario no tiene que aprovisionar servicios de PaaS o de IaaS.
    
    Los servicios al nivel de SaaS se acceden mediante una aplicación cliente, p.e. un navegador (_web browser_). Los usuarios acceden a las aplicaciones de SaaS mediante un usuario y contraseña o mediante un par de claves.
    
      
    
    #### Los cuatro modelos de despliegue del cómputo en la nube
    
    **1. Nube privada**
    
    Los servicios de nube son aprovisionados para el uso exclusivo de una sola organización.
    
    La organización puede ser propietaria de la infraestructura, de un tercero o de una combinación de ambas.
    
    De igual forma, la administración y operación puede ser realizada por la misma organización, por un tercero o una combinación de ambas.
    
    En cuanto a la ubicación, la infraestructura puede estar on-premise (en las instalaciones de la organización), o bien, off-premise (fuera de las instalaciones de la organización).
    
    **2. Nube comunitaria**  
    
    Los servicios de nube son aprovisionados para el uso de una comunidad de usuarios u organizaciones con objetivos compartidos (p.e. empresas, instituciones de gobierno, etc).
    
    Al igual que la nube privada, la propiedad, administración y operación de la infraestructura puede ser de la comunidad, un tercero o una combinación de ambos.
    
    La infraestructura puede estar ubicada en instalaciones de la comunidad, un tercero o una combinación de ambas.  
    
    **3. Nube pública**
    
    Los servicios de nube son aprovisionados para el público en general.
    
    La infraestructura está ubicada en las instalaciones del proveedor de los servicios de nube (Amazon, Microsoft, Google, etc.).
    
    **4. Nube híbrida**
    
    La infraestructura de nube es una composición de dos o más modelos de despliegue (nube privada, nube comunitaria, nube pública).
    
    La comunicación entre las redes de las diferentes nubes, se realiza mediante tecnologías propietarias o estándares que permitan implementar canales de comunicación seguros (como son las VPN).
    
      
    
    **Referencias**
    
    1. [The information Factories](https://www.wired.com/2006/10/cloudware/), George Gilder, WIRED, 2006.
    2. [The NIST Definition of Cloud Computing](https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-145.pdf), Peter Mell, Timothy Grance, NIST U.S. Department of Commerce, 2011.
    3. [Fundamentos y plataformas de cloud computing](https://materials.campus.uoc.edu/daisy/Materials/PID_00286170/pdf/PID_00286170.pdf), Remo Suppi Boldrito, Universitat Oberta de Catalunya, 2a. ed., 2022.
    4. [¿Qué es la nube pública, privada e híbrida?](https://azure.microsoft.com/es-es/overview/what-are-private-public-hybrid-clouds/)
    5. [Cuadrante Mágico para servicios estratégicos de plataforma en la nube](https://www.gartner.com/technology/media-products/reprints/amazon/1-2FTPMD8S-MX.html?trk=44f67619-4f3b-42e8-93b9-32ad8a123845&sc_channel=el)
    
    ![No finalizado; Clase del día - 18/09/2024Aprovisionamiento de rec.... Seleccione para marcar como finalizado](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/i/completion-manual-n "No finalizado; Clase del día - 18/09/2024Aprovisionamiento de rec.... Seleccione para marcar como finalizado")
    
- #### Clase del día - 20/09/2024
    
    **Servicios virtuales a nivel masivo**
    
    El cómputo en la nube es un modelo de arquitectura basado en una infraestructura de cómputo ofrecida como servicios virtuales a nivel masivo.
    
    El concepto clave en el cómputo en la nube es el "servicio", así, se ofrece:  
    
    - IaaS (Infrastructure as a Service) Servicio de creación de infraestructura virtual y física.
    - PaaS (Platform as a Service) Servicios de DBMS, plataformas de desarrollo y pruebas.
    - SaaS (Software as a Service) Servicio de aplicaciones de software.
    - Otros servicios con la terminación "as a Service":
    
    - DaaS (Data as a Service) Servicio de acceso a datos.
    - DRaaS (Disaster Recovery as a Service) Servicio de recuperación de máquinas virtuales ante desastres.
    
      
    
    #### Principios del cómputo en la nube
    
    **Escalabilidad en la nube**
    
    La escalabilidad es la capacidad de un sistema en la nube de aumentar o disminuir los recursos aprovisionados (CPU virtuales y memoria de una máquina virtual, disco de sistema operativo, disco de datos.
    
    La escalabilidad vertical se refiere al crecimiento o descrecimiento de las capacidades de una computadora.
    
    La escalabilidad horizontal se refiere a la creación o eliminación de máquinas virtuales.
    
      
    
    **Disponibilidad en la nube**
    
    La disponibilidad es la capacidad de un sistema en la nube para estar accesible (disponible) en todo momento, de manera que los usuarios puedan acceder el sistema.
    
    La disponibilidad se mide en porcentaje que representa el tiempo durante el cual el sistema está disponible (tiempo de actividad o _uptime_).
    
    La disponibilidad es: 100 x  el tiempo de actividad / tiempo total.
    
    Por ejemplo, si el sistema está disponible 364 días de 365 días, entonces la disponibilidad es del 99.7260%
    
    Los proveedores de nube establecen la disponibilidad de los servicios en un SLA (_Service Level Agreement_) o Acuerdo de nivel de servicio.
    
      
    
    **Confiabilidad en la nube**  
    
    La confiabilidad es la capacidad de un sistema en la nube para funcionar durante largos períodos de tiempo sin interrupciones.
    
    Para garantizar la confiabilidad, los proveedores de nube implementan diversas estrategias, por ejemplo:
    
    **Geo-Redundant Storage**. La replicación de los respaldos en regiones a cientos de kilómetros de la región actual.
    
    **Zona de disponibilidad**. Uno o más datacenters equipados con su propia alimentación, refrigeración y red.
    
    **Dominios de error**. Las máquinas virtuales que pertenecen a un mismo dominio de error comparten la misma fuente de alimentación y red física.
    
    **Dominios de actualización**. Las máquinas virtuales dentro de un mismo dominio de actualización se reiniciarán simultáneamente durante el mantenimiento planeado. Solo se reiniciará un dominio de actualización a la vez.
    
    **Balanceo de carga**. Un balanceador de carga permite escalar un sistema, y al mismo tiempo evita puntos únicos de falla aumentando la disponibilidad.
    
    **Site Recovery**. Permite replicar y recuperar máquinas virtuales en caso de falla o desastre.
    
    **Respaldos**. Copia de seguridad de máquinas virtuales y archivos, permitiendo la recuperación de los datos en caso de _ransomware_, pérdida o corrupción de los datos
    
    **Alta disponibilidad en DBMS**. Crea una réplica de la base de datos en una zona de disponibilidad diferente.
    
      
    
    **Transparencia**
    
    La transparencia es la capacidad de los usuarios para acceder los recursos de nube sin la necesidad de conocer los detalles de la infraestructura de nube.
    
      
    
    Podemos dividir la transparencia en siete categorías:
    
      
    
    **Transparencia en el acceso a los datos.** Los usuarios y aplicaciones acceden a los datos en la nube de manera estandarizada.
    
      
    
    **Transparencia de ubicación.** Los usuarios de nube acceden a los recursos independientemente de su localización física.
    
      
    
    **Transparencia de migración.** Los usuarios de nube no son afectados por la migración de los datos y de los procesos que pueda realizar la plataforma.
    
      
    
    **Transparencia de reubicación.** La transparencia de reubicación se refiere a la capacidad de la nube de cambiar la ubicación de un recurso mientras está en uso, sin que el usuario que accede el recurso se vea afectado.
    
      
    
    **Transparencia de replicación.** La transparencia de replicación es la capacidad de la nube de ocultar la existencia de recursos replicados.
    
      
    
    **Transparencia de concurrencia.** La transparencia de concurrencia se refiere a la capacidad de la nube de ocultar el hecho de que varios usuarios y procesos comparten los diferentes recursos de manera concurrente.
    
      
    
    **Transparencia ante fallas.** La transparencia ante fallas es la capacidad de la nube de ocultar una falla.
    
      
    
    Por ejemplo, si un sistema que se encuentra totalmente replicado, cuando el sistema principal falla entonces el usuario accederá de manera transparente a la réplica del sistema.
    
      
    
    Más adelante en el curso veremos cómo replicar un sistema completo en la nube utilizando un administrador de tráfico de red y cómo implementar sistemas tolerantes a fallas en la nube mediante balance de carga.
    
      
    **Rendimiento**  
      
    El rendimiento es la eficiencia con la que un sistema en la nube utiliza los recursos de nube, incluyendo la capacidad de procesamiento, almacenamiento, ancho de banda, entre otros recursos.  
    
    **Desempeño**
    
    El desempeño se refiere a la velocidad con la ejecuta un sistema en la nube.
    
    El desempeño depende de las técnicas de programación y del rendimiento del sistema. El objetivo es mantener el sistema funcionando de manera consistente incluso bajo cargas de trabajo pesadas.
    
      
    
    **Servicios virtuales a nivel masivo**
    
    El cómputo en la nube es un modelo de arquitectura basado en una infraestructura de cómputo ofrecida como servicios virtuales a nivel masivo.
    
    El concepto clave en el cómputo en la nube es el "servicio", así, se ofrece:  
    
    - IaaS (Infrastructure as a Service) Servicio de creación de infraestructura virtual y física.
    - PaaS (Platform as a Service) Servicios de DBMS, plataformas de desarrollo y pruebas.
    - SaaS (Software as a Service) Servicio de aplicaciones de software.
    - Otros servicios con la terminación "as a Service":
    
    - DaaS (Data as a Service) Servicio de acceso a datos.
    - DRaaS (Disaster Recovery as a Service) Servicio de recuperación de máquinas virtuales ante desastres.
    
      
    
    **La elasticidad en la nube**
    
    Debido a que el cómputo en la nube está basado fundamentalmente en la virtualización de los recursos informáticos, este modelo de arquitectura ofrece una ventaja única, la posibilidad de hacer crecer y decrecer los recursos aprovisionados.
    
    Supongamos un servicio de streaming bajo demanda, como es el caso de Netflix. En este tipo de servicio la demanda crece los fines de semana y decrece los días entre semana.
    
    Si el proveedor del servicio no aprovisiona los recursos suficientes para atender la demanda del fin de semana, entonces muchos usuarios se quedarán sin servicio.  
    
    Por otra parte, si el proveedor del servicio aprovisiona los recursos necesarios para atender a sus usuarios el fin de semana, estos recursos estarán subutilizados los días entre semana, lo cual resulta en pérdidas económicas.
    
    Sin lugar a dudas, el éxito que han alcanzado las empresas proveedoras de streaming bajo demanda, se debe a que su modelo de negocio está basado en la posibilidad que les ofrece la nube para crecer y decrecer los recursos aprovisionados, a esta característica de la nube se le llama _elasticidad_.  
    
    El cómputo elástico es la habilidad de hacer crecer y decrecer rápidamente la capacidad de cómputo (CPUs), la memoria y el almacenamiento para adaptarse a la demanda.  
    
    Para implementar el cómputo elástico se utilizan herramientas de monitoreo, las cuales aprovisionan y des-aprovisionan recursos conforme son necesarios, sin detener la operación.
    
    Sin embargo, hay proveedores de nube que afirman que no existe tal cosa como "nube privada", ya que el tema de elasticidad se ve acotado en un equipo "privado" debido a la limitada escalabilidad.  
    
    En cambio, en la nube pública la escalabilidad es casi ilimitada, ya que si se agotan los recursos de un data center, sin ningún problema se puede escalar a otro data center, ya sea del mismo proveedor o de otros proveedores.  
    
    Una característica importante de la nube (pública) es "pagar por lo que se usa", esto significa que solo se paga por los recursos aprovisionados.
    
    En el caso de un centro de cómputo tradicional (también es el caso de la "nube privada") la empresa paga por todo el equipo, lo use a toda su capacidad o no.  
    
    Consideremos la siguiente gráfica:
    

    
    **Escenario On-premise  
    **
    
      
    
    Al inicio los requerimientos informáticos de la empresa son pocos, sin embargo ésta debe hacer una **gran inversión inicial** ya que debe adquirir el equipo que le permita operar durante un periodo de tiempo determinado.
    
      
    
    Para saber cuál será la inversión inicial  se deberá hacer una _planeación de capacidad_.
    
      
    
    Suponiendo que la empresa crece, entonces en determinado momento deberá realizar la actualización de su equipo informático.
    
      
    
    Entonces se deberá hacer una planeación de capacidad para establecer el tamaño de la inversión, estimando un tiempo determinado de operación.
    
      
    
    No obstante las previsiones, la empresa podría decrecer, por tanto los requerimientos informáticos también decrecen. El costo de la actualización no se recupera, incluso, en poco tiempo el equipo se hará obsoleto.  
    
      
    
    **Escenario nube  
    **
    
    Ahora supongamos que la empresa utiliza servicios en la nube. Entonces la **inversión inicial es mínima**, ya que la empresa contratará los servicios indispensables para operar. Conforme la empresa crece, la elasticidad de la nube permite adecuar el tamaño de la infraestructura informática de acuerdo a las necesidades.
    
    Si la empresa decrece, también decrecen sus necesidades y el costo de la infraestructura informática. En la gráfica, las barras corresponden al costo de los servicios de nube. Podemos ver que este costo se ajusta a las necesidades de la empresa.  
    
    Podemos concluir que al utilizar los servicios de nube se optimiza la relación costo/beneficio, ya que solo pagamos lo que realmente usamos.
    
      
    
    **Referencia**
    
    [What is elastic computing or cloud elasticity?](https://azure.microsoft.com/en-us/overview/what-is-elastic-computing/)  
    
      
    
    #### Actividades individuales a realizar
    
      
    
    Haremos un ejercicio de elasticidad vertical en la nube, modificaremos el tamaño de un máquina virtual y el tamaño del disco de sistema operativo.
    
      
    
    **Cambiar el tamaño de una máquina virtual**
    
    Para cambiar el tamaño de la memoria RAM y el número de CPU virtuales de una máquina virtual:
    
    1. Ejecutar el portal de Azure.
    2. Seleccionar la opción "Máquinas virtuales".
    3. Seleccionar la máquina virtual a modificar.
    4. Seleccionar la opción "Tamaño".
    5. Seleccionar el tamaño requerido (vCPU, RAM)  
        
    6. Dar clic al botón "Cambiar tamaño"
    7. Dar clic en la campana de notificaciones para verificar que el cambio se haya realizado con éxito.  
        
    8. Encender la máquina virtual.
    
    **Cambiar el tamaño del disco de sistema operativo  
    **
    
    Para cambiar el tamaño del disco de sistema operativo de una máquina virtual:  
    
    1. Ejecutar el portal de Azure.
    2. Seleccionar la opción "Máquinas virtuales".
    3. Seleccionar la máquina virtual a modificar.
    4. Detener la máquina virtual.
    5. En el menú "Configuración" seleccionar la opción "Discos".
    6. Seleccionar en la columna "Nombre del disco" el disco a cambiar de tamaño.
    7. Seleccionar "Tamaño y rendimiento" en el menú Configuración.
    8. Seleccionar el nuevo tamaño del disco, notar que **no se puede reducir el tamaño del disco**, solo se puede aumentar.
    9. Dar clic en el botón "Cambiar tamaño".
    10. Dar clic en la campana de notificaciones para verificar que el cambio se haya realizado con éxito.
    11. Encender la máquina virtual.
    12. Ingresar a la máquina virtual mediante ssh y ejecutar el comando "df" para ver el tamaño del disco donde está instalado el sistema operativo.
    
      
    
    ![No finalizado; Clase del día - 20/09/2024Servicios virtuales a ni.... Seleccione para marcar como finalizado](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/i/completion-manual-n "No finalizado; Clase del día - 20/09/2024Servicios virtuales a ni.... Seleccione para marcar como finalizado")
    
- #### Clase del día - 24/09/2024
    
      
    
    #### Máquinas y redes virtuales
    
    **Classless Inter-Domain Routing (CIDR)**
    
    La notación **CIDR** (_Classless Inter-Domain Routing_) o enrutamiento de dominios sin clases es una notación que agrega un sufijo a una dirección IPv4, este sufijo indica el número de unos que forman la máscara de subred a la que pertenece la IP, por ejemplo: **192.54.20.10/24** indica que la IP es 192.54.20.10 y la máscara de subred es 255.255.255.0, ya que 25510=111111112 es decir ocho unos binarios, por tanto el sufijo 24 indica que la máscara de subred contiene 24 unos (contados de izquierda a derecha).  
    
    Otro ejemplo es el siguiente: **192.54.20.10/20**, en este caso la máscara de subred correspondiente es: 255.255.240.0 ya que 25510=111111112 y 24010 = 111100002, es decir, 8+8+4= 20 unos.
    
    De esta manera, es posible saber si dos o más IPs en formato CIDR pertenecen a la misma subred, solo es necesario verificar que las IPs coinciden en los N primeros bits, donde N es el sufijo que precede a la diagonal "/".
    
    La notación CIDR permite implementar redes con una variedad en el número de hosts, a esta propiedad se le llama máscara de subred de longitud variable (VLSM: **Variable Length Subnet Mask**).
    
    Por ejemplo, supongamos que tenemos dos computadoras con las siguientes IP:
    
    192.30.50.20/22  
    192.30.48.10/22
    
    ¿Estas computadoras pertenecen a la misma subred?
    
    Primero convertimos cada IP a binario. Entonces verificamos que los primeros 22 dígitos (de izquierda a derecha) coincidan. 
    
    192.030.050.020 = 11000000 00011110 00110010 00010100  
    192.030.048.010 = 11000000 00011110 00110000 00001010  
    255.255.252.000 = 11111111 11111111 11111100 00000000  (22 unos)
    
    En efecto, los primeros 22 dígitos binarios coinciden en ambas IPs, por tanto las dos computadoras pertenecen a la misma subred.
    
    **Espacios de direcciones IP**
    
    La notación CIDR permite definir espacios de direcciones IP en una red.
    
    Un espacio de direcciones es un intervalo de direcciones IP definido en notación CIDR.
    
    Por ejemplo, 10.2.0.0/16 indica el intervalo de direcciones IP entre 10.2.0.0 y 10.2.255.255, un total de 65,536 direcciones IP.
    
    El número total de direcciones IP que contiene un espacio de direcciones se puede calcular utilizando el sufijo CIDR, en el caso anterior el número de direcciones se calcula de la siguiente manera: 2(32-16)=216=65536.
    
    Por otra parte el sufijo /32 define un espacio de direcciones IP con un número de direcciones IP igual a: 2(32-32)=20=1
    
      
    
    **Redes virtuales en Azure**
    
    Cuando se crea una máquina virtual en Azure se crea por default:
    
    - Una red virtual (**VNet**).
    - Una subred.
    - Una interface de red (**NIC**, _Network Interface Card_) incluyendo una IP privada.
    - Un grupo de seguridad de red (**NSG**, _Network Security Group_).
    - Una IP pública.
    - Un disco de sistema operativo.
    
    **Grupo de recursos**
    
    Un grupo de recursos es similar a un directorio de sistema operativo.
    
    Un grupo de recursos puede contener diferentes recursos de Azure.
    
    Cuando se elimina un grupo de recursos también se eliminan los recursos que contiene el grupo de recursos.  
    
    *******
    
    **Red virtual (VNet)**
    
    Una red virtual es una red privada en Azure.
    
    Las computadoras conectadas a una red virtual pueden comunicarse en forma segura utilizando sus direcciones IP privadas debido a que las direcciones IP privadas no son visibles desde Internet.
    
    Una red virtual está compuesta por uno o más espacios de direcciones IPv4.
    
    Un espacio de direcciones es un intervalo de direcciones IP definido en notación CIDR.  
    
    Los intervalos de direcciones IP en una red virtual no se superponen, es decir, los intervalos no tienen direcciones IP en común.
    
    Por ejemplo, 10.2.0.0/16 indica el intervalo 10.2.0.0 a 10.2.255.255, un total de 65,536 direcciones.
    
    El tamaño máximo del espacio de direcciones de una red virtual es /8 (en notación CIDR, 224=16,777,216 direcciones IP).
    
    Ver: [Agregar o quitar un rango de direcciones](https://docs.microsoft.com/es-es/azure/virtual-network/manage-virtual-network#add-or-remove-an-address-range).  
    
      
    
    **Subred**
    
    Una red virtual puede tener una o varias subredes.
    
    Cada subred se define como un intervalo de direcciones IP dentro de la red virtual.
    
    Cuando se crea una red virtual, se crea por default una subred llamada “default”. Esta subred puede modificarse o eliminarse.
    
    El tamaño mínimo de una subred es /29 (23=8 direcciones IP) y el máximo /8 (224=16,777,216 direcciones IP).
    
    Dos computadoras conectadas a diferentes subredes dentro de una misma red virtual, se pueden comunicar.
    
      
    
    **Grupo de seguridad de red**
    
    Un grupo de seguridad de red (NSG, _Network Security Group_) es un conjunto de reglas de entrada y reglas de salida para los puertos.
    
    Las reglas de puerto de **entrada** controlan las conexiones TCP y paquetes UDP que vienen del exterior de la máquina virtual, mientras que las reglas de puerto de **salida** controlan las conexiones TCP y paquetes UDO que salen de la máquina virtual.
    
    Notar que una vez que se establece la conexión TCP, la comunicación es bidireccional, es decir, la computadora que se conecta (cliente) puede enviar y recibir datos de la computadora a la que se conecta (servidor),
    
    Cada regla de **entrada** permite/deniega conexiones TCP o paquetes UDP **desde:**
    
    - Una dirección IP de origen específica.
    - Un intervalo de direcciones IP de origen.
    - Cualquier dirección IP de origen.
    - Un intervalo de puertos de origen.
    - Un puerto de origen específico.
    - Cualquier puerto de origen.
    
    Cada regla de **salida** permite/deniega conexiones TCP o paquetes UDP **h****acia:**
    
    - Una dirección IP de destino específica.
    - Un intervalo de direcciones IP de destino.
    - Cualquier dirección IP de destino.
    - Un intervalo de puertos de destino,.
    - Un puerto de destino específico.
    - Cualquier puerto de destino.
    
      
    
    También se puede configurar si se permite o deniega un protocolo específico (TCP, UDP o ICMP) o si se permite o deniega cualquier protocolo.
    
    A cada regla del grupo de seguridad de red se le asigna una prioridad, de tal manera que las reglas se aplican de menor a mayor prioridad, es decir, las reglas con menor prioridad tienen mayor precedencia.
    
    Por ejemplo, si una regla con menor prioridad permite el tráfico y otra regla con mayor prioridad deniega el mismo tráfico, entonces se aplicará la primera regla y se ignorará la segunda.
    
    Un grupo de seguridad de red puede asociarse a nivel subred y a nivel interface de red.
    
    Un mismo grupo de seguridad de red puede asociarse a varias subredes y varias interfaces de red.
    
    Por default todo el tráfico que viene de un balanceador de carga o de la red virtual es permitido, y todo el tráfico que viene de Internet es denegado, por tanto para cambiar esto es necesario crear las reglas necesarias para controlar el tráfico de entrada y de salida.
    
    En la siguiente figura podemos ver cómo dos computadoras en la misma red virtual pueden comunicarse sin restricciones.
    
    Por otra parte, para conectar las computadoras a Internet es conveniente configurar las reglas de entrada y de salida.
    

    
    Debido a que las direcciones IP en una red virtual son privadas, para comunicar dos computadoras conectadas a diferentes redes virtuales se deberá utilizar las direcciones IP públicas de las computadoras:  
      
    

    
      
    
    **Interfaz de red**
    
    Una interfaz de red (NIC, _Network Interface Card_) permite a una máquina virtual conectarse a la red virtual.
    
    Una máquina virtual puede tener una o más interfaces de red.
    
    Cada interfaz de red tiene al menos una **configuración IP**.
    
    Una configuración IP contiene una IP privada y opcionalmente una IP pública.
    
    A una configuración IP se le puede asociar una IP pública, la cual podrá ser utilizada por la máquina virtual para conectarse a Internet.  
      
    Existen dos tipos de configuraciones IP: la "Principal" y las "Secundarias". Solo la IP pública de la configuración "Principal" es visible a Internet. La configuración "Principal" no se puede eliminar.  
      
    Una interfaz de red se puede crear y posteriormente se puede agregar a una máquina virtual.  
    Una IP pública también se puede crear y posteriormente se puede asociar a una configuración IP.  
    **  
    Referencias**  
    
    1. [¿Qué es Azure Virtual Network?](https://learn.microsoft.com/es-es/azure/virtual-network/virtual-networks-overview)
    2. [Network security groups](https://learn.microsoft.com/en-us/azure/virtual-network/network-security-groups-overview)
    
      
    
    #### Actividades individuales a realizar
    
      
    
    **Creación de una red virtual en Azure**
    
    1. Ingresar al portal de Azure.  
    
    2. Ingresar "Redes virtuales" en el campo "Buscar recursos, servicios y documentos".
    
    3. Dar clic en el botón "+Crear".  
    
    4. Seleccionar el grupo de recursos o crear uno nuevo.  
    
    5. Ingresar el nombre de la red virtual en el campo "Nombre de red virtual".
    
    6. Seleccionar la región donde se creará la red virtual (por ejemplo: East US)
    
    7. Seleccionar la opción "Direcciones IP".
    
    Por default aparece un intervalo de direcciones con una subred "default".
    
    8. Para agregar más intervalos de direcciones escribir cada intervalo en notación CIDR en el campo que aparece abajo del último intervalo definido.
    
    9. Para agregar una subred dar clic en "+Agregar una subred":
    
    9.1 Ingresar el nombre de la subred.
    
    9.2 Ingresar el intervalo de direcciones de la subred en formato CIDR, este intervalo debe estar dentro del espacio de direcciones.
    
    10. Dar clic en el botón "Revisar y crear".  
    
    11. Dar clic en el botón Crear.
    
    12. Dar clic en el botón "Ir al recurso" para ver la red virtual creada.
    
    **Creación de un grupo de seguridad de red**
    
    1. En la página de inicio de Azure buscar "Grupos de seguridad de red".  
    
    2. Seleccionar "+Crear".
    
    3. En el campo "Grupo de recursos" seleccionar el grupo de recursos donde se creará el grupo de seguridad de red o "Crear nuevo".
    
    4. Ingresar el nombre del grupo de seguridad.
    
    5. Seleccionar la región. La región del NSG debe ser la misma que las subredes o interfaces de red (NIC) que se asociarán al NSG.
    
    6. Dar clic en el botón "Revisar y crear".
    
    7. Dar clic en el botón "Crear".
    
    8. Dar clic en el botón "Ir al recurso".
    
    9. Para agregar reglas de seguridad de entrada o de salida seleccionar las opciones "Reglas de seguridad de entrada" o "Reglas de seguridad de salida" en el menú "Configuración" en la parte izquierda de la pantalla.
    
      
    
    **Agregar una subred a una red virtual**
    
    1. En la página de inicio buscar "Redes virtuales"  
    
    2. Seleccionar la red virtual donde se creará la subred.
    
    3. Seleccionar "Subredes" en el menú "Configuración" que aparece a la izquierda de la pantalla.
    
    4. Seleccionar la opción "+Subred".
    
    5. Ingresar el nombre de la subred.
    
    6. Ingresar el intervalo de direcciones IP de subred en notación CIDR.
    
    7. Si se quiere asociar un grupo de seguridad de red (NSG) a la subred, seleccionarlo.
    
    8. Dar clic en el botón "Guardar".
    
    Entonces se puede ejecutar ifconfig en la máquina virtual para ver las interfaces y las direcciones IP privadas correspondientes.
    
    **Creación de una máquina virtual y su conexión a una red virtual existente**
    
    Cuando se crea una máquina virtual se puede conectar a una subred de una red virtual existente.
    
    1. Seleccionar el grupo de recursos o crear uno nuevo.
    
    2. Ingresar el nombre de la máquina virtual.
    
    3. Seleccionar la misma región donde se creó la red virtual.
    
    4. Seleccionar la imagen, por ejemplo Ubuntu Server 20.04 LTS - x64 gen.2
    
    5. Seleccionar el tamaño, por ejemplo: Standard_B1s
    
    6. En el campo Tipo de autenticación seleccionar "Contraseña".
    
    7. Ingresar el nombre del usuario y la contraseña.
    
    8. Seleccionar la opción "Discos"
    
    9. Seleccionar el tipo de disco de sistema operativo:, por ejemplo: HDD estándar
    
    10. Seleccionar la opción "Redes".
    
    11. Seleccionar la red virtual a la que se conectará la máquina virtual. Notar que sólo se puede seleccionar las redes virtuales que se encuentran en la misma región.
    
    12. Seleccionar la subred a la que se conectará la máquina virtual.
    
    13. Seleccionar una IP pública existente o "Ninguno" si no se requiere la IP pública. También se puede crear una nueva dirección IP pública seleccionando la opción "Crear".
    
    14. Seleccionar la opción "Administración".
    
    15.  En el campo "Diagnóstico de arranque" seleccionar "Deshabilitar".
    
    16. Dar clic en el botón "Revisar y crear".
    
    17. Dar clic en el botón "Crear".
    
    18. Dar clic en el botón "Ir al recurso".
    
    **Creación de una interfaz de red**  
    
    1. En la página de inicio de Azure buscar "Interfaces de red".  
    
    2. Seleccionar "+Crear".
    
    3. Ingresar el grupo de recursos.
    
    4. Ingresar el nombre de la interfaz de red.
    
    5. Seleccionar la región donde se creará la interface de red. La región deberá ser la misma donde se creó la red virtual a la que se conectará la interface.
    
    6. Seleccionar la red virtual a la que se conectará la interface de red.
    
    7. Seleccionar la subred a la que se conectará la interface de red.
    
    8. En el campo "Asignación de la dirección IP privada" se puede seleccionar una IP dinámica o estática, si se selecciona IP estática se deberá ingresar una dirección IP estática.
    
    9. Seleccionar el grupo de seguridad de red.
    
    10. Dar clic en el botón "Revisar y crear".
    
    11. Dar clic en el botón "Crear".
    
    12. Dar clic en el botón "Ir al recurso".
    
    13. Si se quiere asociar un NSG a la interface seleccionar la opción "Grupo de seguridad de red", seleccionar el NSG y dar clic en la opción "Guardar".
    
      
    
    **Añadir una interface de red a una máquina virtual**
    
    Para añadir (asociar) una interface de red a una máquina virtual:
    
    1. En la página de inicio de Azure buscar "Máquinas virtuales".
    
    2. Seleccionar la máquina virtual.
    
    3. Detener la máquina virtual.
    
    4. Seleccionar la opción "Redes" en el menú "Configuración" que aparece a la izquierda de la pantalla.
    
    5. Seleccionar la opción "Adjuntar interfaz de red".
    
    6. Seleccionar una interfaz de red previamente creada.
    
    7. Dar clic en el botón "Aceptar".
    
    8. En la pantalla "Redes" se puede seleccionar la interface de red conectada.
    
    **Quitar una interface de red de una máquina virtual**
    
    Para quitar (desasociar) una interface de red de una máquina virtual:
    
    1. En la página de inicio de Azure buscar "Máquinas virtuales".
    
    2. Seleccionar la máquina virtual.
    
    3. Detener la máquina virtual.
    
    4. Seleccionar la opción "Redes" en el menú "Configuración" que aparece a la izquierda de la pantalla.
    
    5. Seleccionar la opción "Desasociar interfaz de red".
    
    6. Seleccionar la interface de red a desconectar (desasociar).
    
      
    
    **Agregar una configuración IP a una interface de red**  
    
    1. Buscar "Interfaces de red" en la barra de búsqueda en la pantalla de inicio de Azure.
    
    2. Seleccionar la interfaz de red.
    
    3. Seleccionar "Configuraciones de IP".
    
    4. Dar clic en +"Agregar"
    
    5. Ingresar el nombre de la configuración IP.
    
    6. Seleccionar el tipo de asignación de la IP privada: dinámica o estática.  
    
    7. Seleccionar "Asociar" si se quiere asociar una IP pública a la configuración. Notar que solo la IP pública de la configuración "Principal" es visible a Internet.
    
    Dando clic a los tres puntos que se encuentran a la derecha de una configuración se puede eliminar la configuración. La configuración "Principal" no se puede eliminar.
    
      
    
    **Agregar una IP pública a una máquina virtual  
    **
    
    Para agregar una IP pública a una máquina virtual, es necesario asignar (asociar) la IP pública a la configuración IP principal de la interface de red de la máquina virtual.
    
    1. En la página de inicio de Azure buscar "Máquinas virtuales".
    
    2. Seleccionar la máquina virtual.
    
    3. Seleccionar la opción "Redes" en el menú "Configuración" que aparece a la izquierda de la pantalla.  
    
    4. Seleccionar la interfaz de red.  
    
    5. Seleccionar "Configuraciones de IP".
    
    6. Seleccionar la configuración IP a la que se le asignará la IP pública.
    
    7. Checar el campo "Asociar dirección IP pública"
    
    8. En el campo "Dirección IP pública" seleccionar la IP pública o crear una nueva.
    
    9. Dar clic al botón "Guardar".  
    
    10. Cerrar la ventana.
    
      
    **Quitar una IP pública a una máquina virtual  
    **
    
    Para quitar la IP pública a una máquina virtual, es necesario desasociar la IP pública de la configuración IP principal de la interface de red de la máquina virtual.
    
    1. En la página de inicio de Azure buscar "Máquinas virtuales".
    
    2. Seleccionar la máquina virtual.
    
    3. Seleccionar la opción "Redes" en el menú "Configuración" que aparece a la izquierda de la pantalla.  
    
    4. Seleccionar la interfaz de red.  
    
    5. Seleccionar "Configuraciones de IP".
    
    6. Seleccionar la configuración IP a la que se le asignará la IP pública.
    
    7. En el campo "Asociar dirección IP pública" quitar el checado.
    
    8. Dar clic al botón "Guardar".  
    
    9. Cerrar la ventana.
    
      
      
    
    ![No finalizado; Clase del día - 24/09/2024Máquinas y redes virtual.... Seleccione para marcar como finalizado](https://m4gm.com/moodle/theme/image.php/fordson/core/1628296193/i/completion-manual-n "No finalizado; Clase del día - 24/09/2024Máquinas y redes virtual.... Seleccione para marcar como finalizado")
    
- #### Clase del día - 25/09/2024
    
      
    
    **Puerta de enlace de red virtual (VPN Gateway)  
    **  
    Una puerta de enlace de red virtual (_Virtual Network Gateway o VPN Gateway_)  es un gateway implementado en software el cual permite conectar, mediante un canal encriptado, redes virtuales (VNet) entre sí o bien redes virtuales con redes on-premise.  
      
    Para conectar dos redes virtuales se requiere crear dos puertas de enlace de red virtual (Virtual Network Gateway), una para cada red virtual a interconectar.
    
    A la conexión de dos redes virtuales se le conoce como VPN VNet-to-VNet.  
      
    

    
    Fuente: Configure a VNet-to-VNet VPN gateway connection by using the Azure portal
    
      
    
    Por otra parte, para conectar una red on-premise con una red virtual (VNet) se requiere crear una puerta de enlace virtual para la red virtual y configurar un router en la red on-premise.
    
    A la conexión de una red on-premise a una red virtual se le conoce como VPN Site-to-Site o **nube híbrida**.  
    
      
      
    **Subred de puerta de enlace  
    **  
    Antes de crear un VPN gateway es necesario crear una subred de gateway (_gateway subnet_), esta subred contiene las direcciones IP que utilizarán las máquinas virtuales y servicios que implementarán el VPN gateway.  
      
    La subred de gateway debe llamarse "GatewaySubnet", este nombre le indica a Azure que se trata de la subred donde desplegará el VPN gateway.  
      
    Ver: [About VPN Gateway configuration settings](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-vpn-gateway-settings)  
      
      
    
    **Modelo de red de Azure**  
      
    El siguiente diagrama de clases muestra la relación entre los diferentes componentes de una red virtual en Azure:
    

    
      
    
    #### Actividades individuales a realizar
    
      
    
    **Creación de una Puerta de enlace de red virtual (VPN Gateway)**
    
    1. Acceder al portal de Azure.
    
    2. Seleccionar "Crear un recurso".
    
    3. Seleccionar "Puerta de enlace de red virtual".
    
    4. Dar clic en el botón "Crear".
    
    5. Ingresar el nombre del gateway. Notar que el grupo de recursos es el mismo que el grupo de recursos donde está la red virtual.
    
    6. Seleccionar la región.
    
    7. En el campo "Tipo de puerta de enlace" seleccionar "VPN".
    
    8. Seleccionar el SKU "VpnGw2".  
    
    9. EN el campo "Generación" seleccionar "Generation2".
    
    10. Seleccionar la red virtual a la que se conectará el gateway (notar que solo aparecen en la lista las redes virtuales creadas en la misma región).
    
    11. En el campo "Intervalo de direcciones de subred de puerta de enlace" (o el campo "subred") se muestra automáticamente un intervalo correspondiente a la "GatewaySubnet"
    
    12. Seleccionar "Crear" una dirección IP o "Usar existente". Si se va a crear una IP pública ingresar el nombre. Notar que el gateway requiere una dirección IP pública para recibir la conexión de otro gateway.
    
    13. En el campo "Habilitar el modo activo/activo" seleccionar "Deshabilitado".
    
    14. Dar clic en el botón "Revisar y crear".
    
    15. Dar clic en el botón "Crear".
    
    **Nota**. "Setting up a virtual network is free of charge. However, we do charge for the VPN gateway that connects to on-premises and other virtual networks in Azure. This charge is based on the amount of time that gateway is provisioned and available".   
    
    Fuente: [https://azure.microsoft.com/en-gb/pricing/details/vpn-gateway](https://azure.microsoft.com/en-gb/pricing/details/vpn-gateway)
    
      
    
    **Creación de una VPN VNet-to-VNet**
    
      
    
    ![](https://m4gm.com/moodle/pluginfile.php/13577/mod_label/intro/download.png)
    
    Fuente: Configure a VNet-to-VNet VPN gateway connection by using the Azure portal
    
    1. Crear dos redes virtuales en dos regiones diferentes (p.e. East US y West US):
    
    - Se deberá crear en cada red virtual una subred llamada "GatewaySubnet". Esta subred será utilizada por las máquinas virtuales que aprovisiona Azure para ejecutar el gateway. Para crear la subred "GatewaySubnet" al momento de crear la red virtual:
    
    1. Seleccionar la opción "Agregar una subred" en la ventana "Direcciones IP".
    2. En el campo "Propósito de la subred" seleccionar "Virtual Network Gateway".
    3. En el campo "Dirección inicial" ingresar la dirección IP inicial del intervalo de direcciones IP que define la subred.
    4. En el campo "Tamaño" seleccionar el tamaño del intervalo de direcciones IP de la subred.
    5. Dar clic en el botón "Agregar".
    
    - Cada red virtual en un grupo de recursos diferente.
    - Las dos redes virtuales no deberán tener direcciones IP en común (e.d. cada red virtual deberá tener sus espacios de direcciones diferentes).
    
    2. Crear dos puertas de enlace de red virtual (Virtual Network Gateway), una para cada red virtual.  
    
    3. En el cuadro de búsqueda del portal de Azure buscar "Redes virtuales".
    
    4. Seleccionar la primera red virtual a conectar.
    
    5. En el menú "Configuración" que aparece en la parte izquierda de la pantalla seleccionar "Dispositivos conectados" (en la lista aparecen los dispositivos conectados a la red virtual, p.e. interfaces de red virtual, gateways, etc.).
    
    6. Seleccionar el gateway conectado a la red virtual.
    
    7. Ahora vamos a crear una conexión de la primera red a la segunda red y una conexión de la segunda red a la primera red. En el menú "Configuración" que aparece en la parte izquierda de la pantalla seleccionar "Conexiones".
    
    8. Seleccionar "+Agregar" para agregar una nueva conexión.
    
    9. Seleccionar el tipo de conexión: "De VNet a VNet".  
    
    10. Checar el campo "Establecer conectividad bidireccional" (debido a que las conexiones son unidireccionales, al indicar conectividad bidireccional se van a crear dos conexiones de manera que el tráfico pueda ir del primer gateway al segundo gateway y viceversa.  
      
    11. Ingresar el nombre de la primera conexión.  
      
    12. Ingresar el nombre de la segunda conexión.  
    
    13. Seleccionar la región donde se encuentra la primera red virtual a conectar (seleccionada en el paso 3).
    
    14. Seleccionar la pestaña "Opciones".
    
    15. Seleccionar el primer gatewayl (la puerta de enlace virtual seleccionada en el paso 5).
    
    16. Seleccionar el segundo gateway (la puerta de enlace virtual que estará en el otro extremo de la VPN).  
    
    17. Ingresar una clave compartida para el encriptado de la conexión (letras y números).
    
    18. Dar clic en el botón "Revisar y crear".  
    
    19. Dar clic en el botón "Crear".
    
    20. Para ver el estado de las conexiones, seleccionar ingresar "Todos los recursos" en el cuadro de búsqueda de recursos. Seleccionar la primera conexión (el nombre que se ingresó en el paso 11). El estado deberá ser "Conectado". De igual manera se puede verificar el estado de la segunda conexión.
    
    En general una VPN no se encuentra en estado "conectado" mientras no inicie la transmisión de tráfico.  
    
    21. Ahora se puede crear una maquina virtual en la primera VNet y otra máquina virtual en la segunda VNet. Entonces se puede hacer "ping" de la primera máquina virtual a la segunda y viceversa utilizando las direcciones IP privadas de las máquinas virtuales.
    
    Las máquinas virtuales no responden al "ping" cuando se realiza a través de IP públicas.
    
    **Nota**. Para eliminar los gateways es necesario eliminar primero las conexiones.  
      
    **Referencia  
    **  
    [Configure a VNet-to-VNet VPN gateway connection by using the Azure portal](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-howto-vnet-vnet-resource-manager-portal)